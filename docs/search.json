[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "GRASS Tutorials",
    "section": "",
    "text": "Time series: Subset, import and export\n\n\n\n\n\n\nGRASS GIS\n\n\nTime series\n\n\nraster\n\n\nIntermediate\n\n\nPython\n\n\n\n\n\n\n\n\n\nAug 19, 2024\n\n\nVeronica Andreo\n\n\n\n\n\n\n\n\n\n\n\n\nTime series querying\n\n\n\n\n\n\nGRASS GIS\n\n\nTime series\n\n\nraster\n\n\nvector\n\n\nAdvanced\n\n\nPython\n\n\n\n\n\n\n\n\n\nAug 14, 2024\n\n\nVeronica Andreo\n\n\n\n\n\n\n\n\n\n\n\n\nTime series gap filling\n\n\n\n\n\n\nGRASS GIS\n\n\nTime series\n\n\nraster\n\n\nAdvanced\n\n\nPython\n\n\n\n\n\n\n\n\n\nAug 5, 2024\n\n\nVeronica Andreo\n\n\n\n\n\n\n\n\n\n\n\n\nTime series accumulations\n\n\n\n\n\n\nGRASS GIS\n\n\nTime series\n\n\nraster\n\n\nAdvanced\n\n\nPython\n\n\n\n\n\n\n\n\n\nJul 26, 2024\n\n\nVeronica Andreo\n\n\n\n\n\n\n\n\n\n\n\n\nTime series algebra\n\n\n\n\n\n\nGRASS GIS\n\n\nTime series\n\n\nraster\n\n\nAdvanced\n\n\nPython\n\n\n\n\n\n\n\n\n\nJul 24, 2024\n\n\nVerónica Andreo\n\n\n\n\n\n\n\n\n\n\n\n\nTime series aggregation\n\n\n\n\n\n\nGRASS GIS\n\n\nTime series\n\n\nraster\n\n\nIntermediate\n\n\nPython\n\n\n\n\n\n\n\n\n\nJul 23, 2024\n\n\nVerónica Andreo\n\n\n\n\n\n\n\n\n\n\n\n\nTime series management and visualization\n\n\n\n\n\n\nGRASS GIS\n\n\nTime series\n\n\nraster\n\n\nBasic\n\n\nPython\n\n\n\n\n\n\n\n\n\nJul 22, 2024\n\n\nVerónica Andreo\n\n\n\n\n\n\n\n\n\n\n\n\nRunning GRASS in Jupyter Notebooks in Windows with OSGeo4W\n\n\n\n\n\n\nGRASS GIS\n\n\nPython\n\n\nJupyter\n\n\nWindows\n\n\nBasic\n\n\n\n\n\n\n\n\n\nJun 15, 2024\n\n\nCaitlin Haedrich\n\n\n\n\n\n\n\n\n\n\n\n\nMaking plots with GRASS GIS\n\n\n\n\n\n\nGRASS GIS\n\n\nPlotting\n\n\nline\n\n\nhistogram\n\n\nboxplot\n\n\nBasic\n\n\n\n\n\n\n\n\n\nApr 25, 2024\n\n\nVeronica Andreo\n\n\n\n\n\n\n\n\n\n\n\n\nGRASS GIS in Google Colab\n\n\n\n\n\n\nGRASS GIS\n\n\nPython\n\n\nJupyter\n\n\nGoogle Colab\n\n\nIntermediate\n\n\n\n\n\n\n\n\n\nApr 12, 2024\n\n\nVeronica Andreo\n\n\n\n\n\n\n\n\n\n\n\n\nQuick comparison: R and Python GRASS packages\n\n\n\n\n\n\nGRASS GIS\n\n\nPython\n\n\nR\n\n\nIntermediate\n\n\n\n\n\n\n\n\n\nApr 1, 2024\n\n\nVeronica Andreo\n\n\n\n\n\n\n\n\n\n\n\n\nFast track to GRASS with R: the rgrass package\n\n\n\n\n\n\nGRASS GIS\n\n\nR\n\n\nrgrass\n\n\nIntermediate\n\n\n\n\n\n\n\n\n\nMar 29, 2024\n\n\nVeronica Andreo\n\n\n\n\n\n\n\n\n\n\n\n\nFast track to GRASS & Python in Jupyter Notebooks\n\n\n\n\n\n\nGRASS GIS\n\n\nPython\n\n\nJupyter\n\n\nIntermediate\n\n\n\n\n\n\n\n\n\nMar 25, 2024\n\n\nVeronica Andreo\n\n\n\n\n\n\n\n\n\n\n\n\nFast track to get you started with GRASS GIS\n\n\n\n\n\n\nGRASS GIS\n\n\nBasic\n\n\nGet started\n\n\nInstall\n\n\nImport\n\n\n\n\n\n\n\n\n\nMar 19, 2024\n\n\nVeronica Andreo\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "fast_track.html",
    "href": "fast_track.html",
    "title": "Fast track to get you started with GRASS GIS",
    "section": "",
    "text": "In this notebook we will walk you through 5 simple steps to get you started with GRASS GIS."
  },
  {
    "objectID": "fast_track.html#step-1-install-the-software",
    "href": "fast_track.html#step-1-install-the-software",
    "title": "Fast track to get you started with GRASS GIS",
    "section": "Step 1: Install the software",
    "text": "Step 1: Install the software\nGRASS GIS is available on Windows, Linux and macOS. The binaries for Windows and macOS can be found at https://grass.osgeo.org/download/.\nWhich version to choose? We recommend the current release version, which at the time of writing this post is 8.4.\nIf you like testing the latest and greatest, you can go for the preview version which is updated daily and reflects the latest state of the source code.\nLet’s see an example of how to install GRASS GIS on Linux/Ubuntu:\nsudo add-apt-repository ppa:ubuntugis/ubuntugis-unstable\nsudo apt-get update\nsudo apt-get install grass grass-gui grass-dev\nOn Windows, you can either select the standalone installer which will bring GRASS GIS bundeled with all its dependencies or use the OSGeo for Windows (OSGeo4W) meta-installer that will allow you to install many other geospatial software packages and will resolve all dependencies for you.\n\n\n\nInstall GRASS with OSGeo4W installer"
  },
  {
    "objectID": "fast_track.html#step-2-open-grass-gis",
    "href": "fast_track.html#step-2-open-grass-gis",
    "title": "Fast track to get you started with GRASS GIS",
    "section": "Step 2: Open GRASS GIS",
    "text": "Step 2: Open GRASS GIS\nJust double click on the GRASS GIS  icon or type grass in a terminal. In any case, you’ll get both the terminal and the graphical user interface (GUI). You can use GRASS tools in either. It’s a matter of taste, task on hand and habit, too.\n\n\n\nGRASS Graphical User Interface and terminal\n\n\nGRASS GUI has a single window layout by default, but it is also possible to minimize and/or dock/undock the panels. On the right, you can find the data browser which allowa you to navigate through your projects and data, and the layers panel showing displayed layers. The panel in the middle is the map display. You can add additional ones if you need using . Finally, on the right there are multiple tabs where you can find a searchable tools’ tree similar to the Processing toolbox in QGIS, a console where you can type GRASS commands, the history of executed commands in case you want to re-run a task and a simple Python console where you can use the GRASS Python API.\n\n\n\n\n\n\nNote\n\n\n\nSee this example of the GRASS GIS single window GUI with multiple map displays:"
  },
  {
    "objectID": "fast_track.html#step-3-create-a-project",
    "href": "fast_track.html#step-3-create-a-project",
    "title": "Fast track to get you started with GRASS GIS",
    "section": "Step 3: Create a project",
    "text": "Step 3: Create a project\nWhen you open GRASS GIS for the first time, a new directory is created in your home folder. This directory is called grassdata by default and stores all your GRASS projects. GRASS projects are simply folders storing your geospatial data with common coordinate reference system (CRS), ensuring consistency of your data. At the project level, data is further organized into subprojects called mapsets, which you can use to manage different subregions or analyses within a project. Each project contains a special mapset called PERMANENT, which is used to store source datasets for your analysis that can be easily accessed from other mapsets.\nWithin the grassdata directory you will see a sample project called world_latlong_wgs84 which contains the PERMANENT mapset, with a sample vector layer. While there are other sample data sets that you could download to play around with GRASS GIS and test it, you most likely have some data of your own that you want to process and analyse. Therefore, the third step is to create a new project and select its CRS by its name, EPSG code or take it from your input data. Let’s see a simple way to create a project in GRASS GUI. You can either click over “Create new project” in the info bar or use  icon.\n\n\n\nCreate a new GRASS project\n\n\nProjects can also be created from command line when starting GRASS. This is how we would create an UTM20S project, for example:\ngrass -c EPSG:32720 /home/username/grassdata/utm20s\nAlternatively, pass a georeferenced file which CRS will be used to create your project:\ngrass -c myraster.tif /home/username/grassdata/utm20s"
  },
  {
    "objectID": "fast_track.html#step-4-import-your-data",
    "href": "fast_track.html#step-4-import-your-data",
    "title": "Fast track to get you started with GRASS GIS",
    "section": "Step 4: Import your data",
    "text": "Step 4: Import your data\nOnce you have created your GRASS project, you’ll notice it contains the PERMANENT mapset inside. You can import your data there or optionally you could create other mapsets to organize your work.\nWhy do we need to import data? GRASS has a native format for raster and vector data to facilitate robust and efficient analysis and manipulation of geospatial data. One advantage of this structure is that you can easily zip your mapsets or projects to share with your colleagues. And guess what? Not only data will be there but also the history of commands you have executed on them!\nSo, how do we import data? Let’s see an example for raster and vector data formats. For imports with optional re-projection, you can use  and  icons from the Data panel bar.\nIn the first case, we import 10m resolution bands from Copernicus Sentinel 2 scenes that can be found here. Note that we can import all files within a directory if we specify the extension of such files, jp2 in this case.\n\nIn another example, we import a GeoPackage with different CRS. Data will be automatically reprojected.\n\nMaps will be added to the layer tree and displayed automatically.\n\nWe could execute the same tasks from either the “Console” tab or the terminal. In that case, the commands to import a raster and a vector map would be:\nr.import input=myraster.tif output=myraster\nv.import input=myvector.gpkg output=myvector"
  },
  {
    "objectID": "fast_track.html#step-5-set-the-computational-region",
    "href": "fast_track.html#step-5-set-the-computational-region",
    "title": "Fast track to get you started with GRASS GIS",
    "section": "Step 5: Set the computational region",
    "text": "Step 5: Set the computational region\nThe last important step, especially if you are working with raster data, is to set the computational region. This is the extent and resolution of your region of interest or study area, and it will affect all your raster processing, i.e., output rasters will have their extent and spatial resolution equal to the computational region. You can set the computational region to the extent of a vector map, to the extent and resolution of a raster map or manually introducing the north, south, east, and west coordinates.\nWhy do we need a computational region? When combining data with different resolution and extents, it helps keeping results consistent. Also, raster data might be large and running processes on them might take a while. Setting a smaller computational region allows you to test your algorithms and parameter values without the need to clip input maps, so once you are happy with the result, you can run the process for the whole raster extent.\n\nThe computational region can be changed interactively from the map display by selecting a region with your mouse, or using the g.region tool both from the GUI and command line.\n\nInteractive:\n\n\n\nUsing g.region from the contextual menu after right click on a layer:\n\n\n\nUsing g.region from the main menu in the GUI:\n\n\nNote how commands are formed when you select options in the GUI. If you use the  button, you can then paste these in a text file and set the basis of your protocol, which can then be generalized into a script or even your own GRASS tool.\n\n\nFrom the console tab or in the terminal:\n\ng.region -p raster=myraster\n\nGetting help\nThere are several sources you can get help from:\n\nManual pages online\ng.manual: eg., g.manual r.info\n--help or --h flag in command line, eg., r.info --h\nTutorials on the website\nJoin the GRASS community chat or subscribe to the mailing list.\n\nYou are ready! Enjoy! \n\n\nThe development of this tutorial was funded by the US National Science Foundation (NSF), award 2303651."
  },
  {
    "objectID": "quick_comparison_r_vs_python_grass_interfaces.html",
    "href": "quick_comparison_r_vs_python_grass_interfaces.html",
    "title": "Quick comparison: R and Python GRASS packages",
    "section": "",
    "text": "In previous tutorials we have gone through some of the basics of using GRASS GIS through/with R and Python. As you might recall then, there’s an R package called rgrass that provides basic functionality to read and write data from and into GRASS database as well as to execute GRASS tools in either existing or temporary GRASS projects. The GRASS Python API, on the other hand, is composed of various packages that provide classes and functions for low and high level tasks, including those that can be executed with rgrass.\nAs you might have noticed there are some parallelisms between the rgrass and grass.script/grass.jupyter packages, i.e., R and Python interfaces to GRASS GIS. In this short tutorial we will go through these similarities in order to highlight the equivalencies and streamline the use of GRASS extensive functionality within R and Python communities.\nLet’s quickly review the equivalencies and go through some examples."
  },
  {
    "objectID": "quick_comparison_r_vs_python_grass_interfaces.html#comparison-examples",
    "href": "quick_comparison_r_vs_python_grass_interfaces.html#comparison-examples",
    "title": "Quick comparison: R and Python GRASS packages",
    "section": "Comparison examples",
    "text": "Comparison examples\nLet’s see how usage examples would look like.\n\nLoad the library: Either if we are working in R or in Python, we need to load the libraries that will, in this case, allow us to interface with GRASS GIS functionality and (optionally) data. For the Python case, we first need to add the GRASS python package path to our system’s path.\n\n\nRPython\n\n\n\nlibrary(rgrass)\n\n\n\n\nimport sys\nimport subprocess\n\nsys.path.append(\n    subprocess.check_output([\"grass\", \"--config\", \"python_path\"], text=True).strip()\n)\n\nimport grass.script as gs\nimport grass.jupyter as gj\n\n\n\n\n\nStart a GRASS GIS session: Once we loaded or imported the packages, we start a GRASS GIS session. In both cases we need to somehow pass the path to a temporary or existing GRASS project. In the case of R, we are also required to pass the path to GRASS GIS binaries, that in the Python case was needed for library import above. Here, it is worth noting that while grass.scrip and grass.jupyter init functions take the same arguments, gj.init also sets other environmental variables to streamline work within Jupyter Notebooks, e.g., overwrite is set to true so cells can be executed multiple times.\n\n\nRPython\n\n\n\nsession &lt;- initGRASS(gisBase = \"/usr/lib/grass83\", # where grass binaries live, `grass --config path`\n                     gisDbase = \"/home/user/grassdata\", # path to grass database or folder where your project lives\n                     location = \"nc_basic_spm_grass7\", # existing project name \n                     mapset = \"PERMANENT\" # mapset name\n                     ) \n\n\n\n\n# With grass.script\ngs.setup.init(path=\"/home/user/grassdata\",\n              location=\"nc_basic_spm_grass7\",\n              mapset=\"PERMANENT\")\n# Optionally, the path to a mapset\ngs.setup.init(\"/home/user/grassdata/nc_basic_spm_grass7/PERMANENT\")\n\n# With grass.jupyter\nsession = gj.init(path=\"/home/user/grassdata\",\n                  location=\"nc_basic_spm_grass7\",\n                  mapset=\"PERMANENT\")\n# Optionally, the path to a mapset\ngj.init(\"/home/user/grassdata/nc_basic_spm_grass7/PERMANENT\")\n\n\n\n\n\nExecute GRASS commands: Both interfaces work pretty similarly, the first argument is always the GRASS module name and then we pass the parameters and flags. While in R we basically use execGRASS() for all GRASS commands, in the Python API, we have different wrappers to execute GRASS commands depending on the nature of their output.\n\n\nRPython\n\n\n\n# Map output\nexecGRASS(\"r.slope.aspect\", \n          elevation = \"terra_elev\", \n          slope = \"slope\",\n          aspect = \"aspect\")\n\n# Text output\nexecGRASS(\"g.region\",\n          raster = \"elevation\",\n          flags = \"p\")\n\n\n\n\n# Map output\ngs.run_command(\"r.slope.aspect\", \n               elevation = \"terra_elev\", \n               slope = \"slope\",\n               aspect = \"aspect\")\n# Text output\ngs.read_command(\"g.region\",\n                raster = \"elevation\",\n                flags = \"p\")\n# Text output - dictionary\ngs.parse_command(\"g.region\",\n                 raster = \"elevation\",\n                 flags = \"p\")\n\n\n\n\n\nRead raster and vector data into other R or Python formats: rgrass functions read_RAST() and read_VECT() convert GRASS raster and vector maps into terra’s SpatRaster and SpatVector objects within R. In the case of Python, we only have such a functionality for GRASS raster maps that can be converted into numpy arrays through gs.array.array(). Vector attribute data however can be converted into pandas data frames using StringIO function within pandas read_csv.\n\n\nRPython\n\n\n\n# Raster\nelevr &lt;- read_RAST(\"elevation\")\n\n# Vector\nschoolsr &lt;- read_VECT(\"schools\")\n\n\n\n\n# Raster\nimport numpy as np\nelev = gs.array.array(\"elevation\")\n\n# Vector\nimport pandas as pd\nfrom io import StringIO\nschoolsp = gs.read_command(\"v.db.select\", map=\"schools\").strip()\ndf = pd.read_csv(StringIO(schoolsp), sep=\"|\")\n\n\n\n\n\nWrite R or Python objects into GRASS raster and vector maps: R terra’s SpatRaster and SpatVector objects can be written (back) into GRASS format with write_RAST() and write_VECT() functions. Within the Python environment, numpy arrays can also be written (back) into GRASS raster maps with the write() method.\n\n\nRPython\n\n\n\n# Raster\nwrite_RAST(elevr, \"elevation_r\")\n\n# Vector\nwrite_VECT(schoolsr, \"schools_r\")\n\n\n\n\n# Raster\nelev.write(mapname=\"elev_np\", overwrite=True)\n\n\n\n\n\nClose GRASS GIS session: In general, just closing R or Rstudio, as well as shutting down Jupyter notebook, will clean up and close the GRASS session properly. Sometimes, however, especially if the user changed mapset within the workflow, it is better to clean up explicitly before closing.\n\n\nRPython\n\n\n\nunlink_.gislock()\n\n\n\n\nsession.finish()"
  },
  {
    "objectID": "quick_comparison_r_vs_python_grass_interfaces.html#final-remarks",
    "href": "quick_comparison_r_vs_python_grass_interfaces.html#final-remarks",
    "title": "Quick comparison: R and Python GRASS packages",
    "section": "Final remarks",
    "text": "Final remarks\nThe examples and comparisons presented here are intended to facilitate the combination of tools and languages as well as the exchange of data and format conversions. We hope that’s useful as starting point for the implementation of different use cases and workflows that suit the needs of users."
  },
  {
    "objectID": "quick_comparison_r_vs_python_grass_interfaces.html#references",
    "href": "quick_comparison_r_vs_python_grass_interfaces.html#references",
    "title": "Quick comparison: R and Python GRASS packages",
    "section": "References",
    "text": "References\n\nGRASS Python API docs\nrgrass docs\n\n\n\nThe development of this tutorial was funded by the US National Science Foundation (NSF), award 2303651."
  },
  {
    "objectID": "time_series/time_series_accumulations.html",
    "href": "time_series/time_series_accumulations.html",
    "title": "Time series accumulations",
    "section": "",
    "text": "In this fourth part of the time series tutorials, we will go through data accumulation. We’ll mostly follow a modified version of the example presented in the t.rast.accumulate and t.rast.accdetect tools."
  },
  {
    "objectID": "time_series/time_series_accumulations.html#t.rast.accumulate",
    "href": "time_series/time_series_accumulations.html#t.rast.accumulate",
    "title": "Time series accumulations",
    "section": "t.rast.accumulate",
    "text": "t.rast.accumulate\nt.rast.accumulate performs temporal accumulations of raster time series. Data accumulations are common in ecology or agriculture, especially temperature accumulation. Usually, to determine if insects or plants can survive in a certain place, a measure of accumulated temperature is used. For example, a certain plant species might need x GDD to bloom, or a mosquito species might need x GDD to complete their development from egg to adult. Therefore, it is usual to accumulate temperature data, but other variables can be accumulated too, e.g. chlorophyll concentration to determine algal bloom occurrences in water bodies.\nt.rast.accumulate expects a STRDS as input that will be sampled by a given granularity. All maps that have the start time during the actual granule will be accumulated with the predecessor granule accumulation result using the raster module r.series.accumulate. The default granularity is 1 day, but any temporal granularity can be set. The start time and the end time of the accumulation process must be set. In addition, a cycle can be specified that defines after which interval of time the accumulation process restarts. The offset option specifies the time that should be skipped between two cycles.\nThe lower and upper limits of the accumulation process can be set, either by using space time raster datasets or by using fixed values for all raster cells and time steps by means of the limits option is used, eg. limits=10,30. The upper limit is only used in the Biologically Effective Degree Days calculation.\nThe output is a new space time raster dataset with the provided start time, end time and granularity containing the accumulated raster maps.\n\nAccumulation using BEDD\nLet’s consider the mosquito Aedes albopictus. Adults require a minimum average temperature of 11 °C to survive. We will compute the Biologically Effective Degree Days (BEDD) from 2014 until 2018 for each year with a granularity of one day. The base temperature will be 11°C, and the upper limit 30°C where adult mosquito survival is known to decrease. Hence the accumulation will start at 11°C and stop at 30°C.\n\n# Accumulation of degree days\ngs.run_command(\"t.rast.accumulate\",\n               input=\"lst_daily\",\n               output=\"mosq_daily_bedd\",\n               basename=\"mosq_daily_bedd\",\n               suffix=\"gran\",\n               start=\"2014-01-01\",\n               stop=\"2019-01-01\",\n               cycle=\"12 months\",\n               method=\"bedd\", \n               limits=\"11,30\")\n\n\n# Get basic info\ngs.run_command(\"t.info\", input=\"mosq_daily_bedd\")\n\n\n\nSuitable areas for mosquitos\nAccording to Kobashayi et al (2002), populations of Aedes albopictus establish where at least 1350 DD are accumulated. These DD should be reached before Oct 1st to consider a place as suitable. Let’s find out when and where that condition is met.\nWe will first discard all cells with BEDD &lt; 1350 from our accumulated time series, and then we will save the day of the year (DOY) where BEDD &gt;= 1350.\n\nexp=\"doy_bedd_higher_1350 = if(mosq_daily_bedd &gt;= 1350, start_doy(mosq_daily_bedd, 0), null())\"\n\ngs.run_command(\"t.rast.algebra\",\n               expression=exp,\n               basename=\"doy_bedd_higher_1350\",\n               suffix=\"gran\",\n               nprocs=6)\n\nThen, we aggregate the doy_bedd_higher_1350 STRDS on an annual basis, as we want to see possible changes among years. We use method=minimum to get the earliest day on which the condition is met each year.\n\ngs.run_command(\"t.rast.aggregate\",\n               input=\"doy_bedd_higher_1350\",\n               method=\"minimum\",\n               granularity=\"1 year\",\n               output=\"annual_doy_bedd_higher_1350\",\n               basename=\"annual_doy_bedd_higher_1350\",\n               suffix=\"gran\",\n               nprocs=6)\n\n\ngs.run_command(\"t.rast.list\",\n                input=\"annual_doy_bedd_higher_1350\",\n                columns=\"id,min,max\")\n\nFollowing Neteler et al (2013), if the 1350 DD are achieved on or before August 1st, a place is considered highly suitable for Aedes albopictus, while if the condition is met after October 1st, the place is not suitable. Everything in between is defined as a linear function of DOY. Once again, we use the temporal algebra to create yearly suitability maps. Note we are using a nested if statement.\n\nexpression=\"suitability = if(annual_doy_bedd_higher_1350 &lt;= 214, 1, if(annual_doy_bedd_higher_1350 &gt; 214 && annual_doy_bedd_higher_1350 &lt;= 274, (274 - annual_doy_bedd_higher_1350)/60.0, if(annual_doy_bedd_higher_1350 &gt; 274, 0)))\"\n\ngs.run_command(\"t.rast.algebra\",\n               expression=expression,\n               basename=\"suitability\",\n               suffix=\"gran\",\n               nprocs=6)\n\nLet’s see how suitable area and suitability values change with time by means of an animation.\n\n# Animation of annual anomalies\nsuitability = gj.TimeSeriesMap(use_region=True)\nsuitability.add_raster_series(\"suitability\", fill_gaps=False)\nsuitability.d_legend(color=\"black\", at=(10,40,2,6))\nsuitability.show()\n\nImpressive, ah? Let’s do some basic math to quantify the suitable area increase from 2014 to 2018. We use r.univar to get the number of non-null cells in each map.\n\nland_cells = gs.parse_command(\"r.univar\", map=\"lst_2014.001_avg\", flags=\"g\")['n']\nsuit_2014 = gs.parse_command(\"r.univar\", map=\"suitability_2014\", flags=\"g\")['n']\nsuit_2018 = gs.parse_command(\"r.univar\", map=\"suitability_2018\", flags=\"g\")['n']\nchange = ((float(suit_2018) - float(suit_2014))/float(land_cells))*100.0\nprint(f\"The increase in suitable area was {change}\")"
  },
  {
    "objectID": "time_series/time_series_accumulations.html#t.rast.accdetect",
    "href": "time_series/time_series_accumulations.html#t.rast.accdetect",
    "title": "Time series accumulations",
    "section": "t.rast.accdetect",
    "text": "t.rast.accdetect\nt.rast.accdetect is used to detect accumulation patterns in temporally accumulated STDRS created by t.rast.accumulate. The start and end time do not need to be the same but the cycle and offset options must be exactly the same that were used in the accumulation process that generated the input STRDS. Minimum and maximum values for pattern detection can be set either by using STRDS or fixed values for all raster cells and time steps (range option).\nUsing STRDS would allow specifying minimum and maximum values for each raster cell and each time step. For example, if you want to detect the germination (minimum value) and harvesting (maximum value) dates for different crops using the growing-degree-day (GDD) method for several years. Different crops may grow in different raster cells and change with time because of crop rotation. Hence we need to specify different GDD germination/harvesting (minimum/maximum) values for different raster cells and different years.\nt.rast.accdetect produces two output STRDS:\n\noccurrence: The occurrence STRDS stores the time in days from the beginning of a given cycle for each raster. These values can be used to compute the duration of the recognized accumulation pattern.\nindicator: The indicator STRDS uses three integer values to mark raster cells as beginning (1), intermediate (2) state or end (3) of an accumulation pattern. These values can be used to identify places with complete cycles.\n\n\nDetection of mosquito generations\nFollowing Kobashayi et al (2002), each mosquito generation might take around 365 DD. Let’s use this reference value to identify how many mosquito generations we could expect over our study area.\n\ncycle = list(range(1, 10))\ncycle_beg = list(range(1, 3286, 365))\ncycle_end = list(range(365, 3286, 365))\n\nfor i in range(1, len(cycle) + 1):\n  \n    print(f\"cycle: {cycle[i-1]} - {cycle_beg[i-1]} {cycle_end[i-1]}\")\n    \n    # Identify generations\n    gs.run_command(\"t.rast.accdetect\",\n                    input=\"mosq_daily_bedd\",\n                    occurrence=f\"mosq_occurrence_gen_{cycle[i-1]}\",\n                    indicator=f\"mosq_indicator_gen_{cycle[i-1]}\",\n                    basename=f\"mosq_gen_{cycle[i-1]}\",\n                    start=\"2014-01-01\",\n                    stop=\"2019-01-01\",\n                    cycle=\"12 months\",\n                    range=f\"{cycle_beg[i-1]},{cycle_end[i-1]}\")\n                      \n    gs.run_command(\"t.rast.aggregate\",\n                    input=f\"mosq_indicator_gen_{cycle[i-1]}\",\n                    output=f\"mosq_gen{cycle[i-1]}_yearly\",\n                    basename=f\"mosq_gen{cycle[i-1]}_yearly\",\n                    granularity=\"1 year\",\n                    method=\"maximum\", \n                    suffix=\"gran\")\n\n    # Keep only complete generations\n    exp=f\"if(mosq_gen{cycle[i-1]}_yearly == 3, {cycle[i-1]}, null())\"\n    gs.run_command(\"t.rast.mapcalc\",\n                    input=f\"mosq_gen{cycle[i-1]}_yearly\",\n                    output=f\"mosq_gen{cycle[i-1]}_yearly_clean\",\n                    basename=f\"mosq_clean_gen{cycle[i-1]}\",\n                    expression=exp)\n  \n    # Duration of each mosquito generation\n    # Beginning\n    gs.run_command(\"t.rast.aggregate\",\n                    input=f\"mosq_occurrence_gen_{cycle[i-1]}\",\n                    output=f\"mosq_min_day_gen{cycle[i-1]}\",\n                    basename=f\"occ_min_day_gen{cycle[i-1]}\",\n                    method=\"minimum\",\n                    granularity=\"1 year\",\n                    suffix=\"gran\")\n    # End\n    gs.run_command(\"t.rast.aggregate\",\n                    input=f\"mosq_occurrence_gen_{cycle[i-1]}\", \n                    output=f\"mosq_max_day_gen{cycle[i-1]}\",\n                    basename=f\"occ_max_day_gen{cycle[i-1]}\",\n                    method=\"maximum\",\n                    granularity=\"1 year\",\n                    suffix=\"gran\")\n    # Difference\n    exp=f\"mosq_max_day_gen${cycle[$i-1]} - mosq_min_day_gen${cycle[$i-1]} + 1\"\n    gs.run_command(\"t.rast.mapcalc\",\n                    input=f\"mosq_min_day_gen{cycle[i-1]},mosq_max_day_gen{cycle[i-1]}\",\n                    output=f\"mosq_duration_gen{cycle[i-1]}\", \n                    basename=f\"mosq_duration_gen{cycle[i-1]}\",\n                    expression=exp)\n\nLet’s now see which is the maximum number of generations in each cell and their median duration per year.\n\n\nMaximum number of generations per year\n\nfor i in range(1, 6):\n    maps = gs.list_grouped(type=\"raster\", pattern=f\"mosq_clean_gen*_{i}\")\n    gs.run_command(\"r.series\",\n                    input=maps,\n                    output=f\"mosq_max_n_generations_{i}\",\n                    method=\"maximum\")\n\nLet’s see an animation:\n\n# List of average maps\nmap_list = gs.list_grouped(type=\"raster\", pattern=\"mosq_max_n_generations_*\")\n\n# Animation with SeriesMap class\nseries = gj.SeriesMap(height = 500)\nseries.add_rasters(map_list)\nseries.d_barscale()\nseries.show()\n\n\n\nMedian duration of mosquito generations per year\n\nfor i in range(1, 6):\n    maps = gs.list_grouped(type=\"raster\", pattern=f\"mosq_duration_gen*_{i}\")\n    gs.run_command(\"r.series\",\n                    input=maps,\n                    output=f\"mosq_med_duration_generations_{i}\",\n                    method=\"median\")\n\nLet’s see an animation:\n\n# List of average maps\nmap_list = gs.list_grouped(type=\"raster\", pattern=\"mosq_med_duration_generations_*\")\n\n# Animation with SeriesMap class\nseries = gj.SeriesMap(height = 500)\nseries.add_rasters(map_list)\nseries.d_barscale()\nseries.show()\n\nWe can now remove all intermediate series and maps:\n\ngs.run_command(\"t.list\", \n                type=\"strds\", \n                where=\"name LIKE '%gen%'\", \n                output=\"to_remove.txt\")\ngs.run_command(\"t.remove\", \n                flags=\"df\", \n                file=\"to_remove.txt\")"
  },
  {
    "objectID": "time_series/time_series_accumulations.html#references",
    "href": "time_series/time_series_accumulations.html#references",
    "title": "Time series accumulations",
    "section": "References",
    "text": "References\n\nNeteler, M., Metz, M., Rocchini, D., Rizzoli, A., Flacio, E., et al. 2013. Is Switzerland Suitable for the Invasion ofAedes albopictus? PLOS ONE 8(12). DOI.\nKobayashi, M., Nihei, N., Kurihara, T. 2002. Analysis of Northern Distribution of Aedes albopictus (Diptera: Culicidae) in Japan by Geographical Information System. Journal of Medical Entomology 39(1), 4–11. DOI.\nGebbert, S., Pebesma, E. 2014. TGRASS: A temporal GIS for field based environmental modeling. Environmental Modelling & Software 53, 1-12. DOI.\nGebbert, S., Pebesma, E. 2017. The GRASS GIS temporal framework. International Journal of Geographical Information Science 31, 1273-1292. DOI.\nTemporal data processing wiki page.\n\n\n\nThe development of this tutorial was funded by the US National Science Foundation (NSF), award 2303651."
  },
  {
    "objectID": "time_series/time_series_management_and_visualization.html",
    "href": "time_series/time_series_management_and_visualization.html",
    "title": "Time series management and visualization",
    "section": "",
    "text": "GRASS GIS was the first FOSS GIS that incorporated capabilities to manage, analyze, process and visualize spatio-temporal data, as well as the temporal relationships among time series and maps within time series.\n\nThe temporal GRASS framework is fully based on metadata and does not duplicate any dataset\nIt is based on a snapshot approach, i.e., it adds time stamps to maps\nA collection of time stamped maps (snapshots) of the same variable are called space-time datasets or STDS\nMaps in a STDS can have different spatial and temporal extents\nSpace-time datasets can be composed of raster, 3D raster or vector maps, and so we call them:\n\nSpace time raster datasets (STRDS)\nSpace time 3D raster datasets (STR3DS)\nSpace time vector datasets (STVDS)\n\nThese STDS objects will then be inputs and (optionally) outputs of temporal tools\n\n\n\n\nTime can be defined as intervals (start and end time) or instances (only start time)\nTime can be absolute (e.g., 2017-04-06 22:39:49) or relative (e.g., 4 years, 90 days)\n\n\n\n\nGRASS temporal tools are named and organized following GRASS core naming scheme. In this way, we have:\n\nt.*: general tools to handle STDS of all types\nt.rast.*: tools that deal with STRDS\nt.rast3d.*: tools that deal with STR3DS\nt.vect.*: tools that deal with STVDS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSetup\n\n\n\nTo run this tutorial locally or in Google Colab, you should install GRASS GIS 8.4+, and download the daily MODIS LST project. This project contains average daily MODIS LST data reconstructed by mundialis GmbH & Co. KG based on Metz et al (2017).\nFollow the Fast track to GRASS GIS and GRASS in Colab tutorials to get you started.\n\n\n\nIn this first tutorial of the “Time series in GRASS GIS” series, we will learn the basics of time series management:\n\ncreation\ndifferent ways of assigning time stamps, i.e., registering\ngetting info\nlisting and selection\ndescriptive stats\nvisualizations"
  },
  {
    "objectID": "time_series/time_series_management_and_visualization.html#the-temporal-grass-framework",
    "href": "time_series/time_series_management_and_visualization.html#the-temporal-grass-framework",
    "title": "Time series management and visualization",
    "section": "",
    "text": "GRASS GIS was the first FOSS GIS that incorporated capabilities to manage, analyze, process and visualize spatio-temporal data, as well as the temporal relationships among time series and maps within time series.\n\nThe temporal GRASS framework is fully based on metadata and does not duplicate any dataset\nIt is based on a snapshot approach, i.e., it adds time stamps to maps\nA collection of time stamped maps (snapshots) of the same variable are called space-time datasets or STDS\nMaps in a STDS can have different spatial and temporal extents\nSpace-time datasets can be composed of raster, 3D raster or vector maps, and so we call them:\n\nSpace time raster datasets (STRDS)\nSpace time 3D raster datasets (STR3DS)\nSpace time vector datasets (STVDS)\n\nThese STDS objects will then be inputs and (optionally) outputs of temporal tools\n\n\n\n\nTime can be defined as intervals (start and end time) or instances (only start time)\nTime can be absolute (e.g., 2017-04-06 22:39:49) or relative (e.g., 4 years, 90 days)\n\n\n\n\nGRASS temporal tools are named and organized following GRASS core naming scheme. In this way, we have:\n\nt.*: general tools to handle STDS of all types\nt.rast.*: tools that deal with STRDS\nt.rast3d.*: tools that deal with STR3DS\nt.vect.*: tools that deal with STVDS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSetup\n\n\n\nTo run this tutorial locally or in Google Colab, you should install GRASS GIS 8.4+, and download the daily MODIS LST project. This project contains average daily MODIS LST data reconstructed by mundialis GmbH & Co. KG based on Metz et al (2017).\nFollow the Fast track to GRASS GIS and GRASS in Colab tutorials to get you started.\n\n\n\nIn this first tutorial of the “Time series in GRASS GIS” series, we will learn the basics of time series management:\n\ncreation\ndifferent ways of assigning time stamps, i.e., registering\ngetting info\nlisting and selection\ndescriptive stats\nvisualizations"
  },
  {
    "objectID": "time_series/time_series_management_and_visualization.html#hands-on",
    "href": "time_series/time_series_management_and_visualization.html#hands-on",
    "title": "Time series management and visualization",
    "section": "Hands-on",
    "text": "Hands-on\nWe begin by loading GRASS package:\n\nimport os\nimport sys\nimport subprocess\n\n# Ask GRASS GIS where its Python packages are\nsys.path.append(\n    subprocess.check_output([\"grass\", \"--config\", \"python_path\"], text=True).strip()\n)\n# Import the GRASS GIS packages we need\nimport grass.script as gs\nimport grass.jupyter as gj\n\nNow we are ready to start a GRASS GIS session in the downloaded project:\n\npath_to_project = \"eu_laea/italy_LST_daily\"\n\n# Start the GRASS GIS Session\nsession = gj.init(path_to_project)\n\n\nExplore the data in the mapset\nLet’s first explore what we have within the italy_LST_daily mapset and display a raster map using the InteractiveMap class from grass.jupyter library.\n\n# List raster elements\nrast = gs.list_grouped(type=\"raster\", pattern=\"lst*\")['italy_LST_daily']\nrast[0:10]\n\n\n# Display raster map with interactive class\nlst_map = gj.InteractiveMap(use_region=True, tiles=\"CartoDB.DarkMatter\")\nlst_map.add_raster(\"lst_2014.005_avg\")\nlst_map.show()\n\n\n\nCreate a time series\nWhen working with the temporal framework, the first step is to create the time series object or STDS. This object is basically a container for maps that are already imported into or linked to our GRASS project, we are not duplicating any data. It consists of a SQLite table that will then store map names and metadata such as spatial extent, temporal extent, min and max values, semantic labels, etc.\nTo create the time series object, we use t.create and we need to define the type (strds, stvds or st3ds), the temporal type (absolute or relative), the output or name of the time series object, a title and a description.\n\n# Create time series \ngs.run_command(\"t.create\",\n               type=\"strds\",\n               temporaltype=\"absolute\",\n               output=\"lst_daily\",\n               title=\"Average Daily LST\",\n               description=\"Gap filled average daily MODIS LST in Celsius - 2014-2018\")\n\nWith t.list we check the object was indeed created and with t.info we can explore details about this recently created object.\n\n# Check it is created\ngs.run_command(\"t.list\",\n              type=\"strds\")\n\n\n# Check time series metadata\nprint(gs.read_command(\"t.info\",\n                      input=\"lst_daily\"))\n\nSince we have not yet registered our LST maps in the time series object, it is empty, i.e., there is no metadata to show.\n\n\nAssign time stamps: register maps\nTo actually fill our time series object with the LST maps, we need to assign time stamps to these maps. For this we use the t.register tool. There are different ways of registering maps. We can either pass a sorted list of maps or a text file with one map per line and optionally start and end dates, and semantic labels. It is also important to understand if our data represent time intervals (e.g. precipitation over a period of time) or time instances (events), and in the case of intervals, if they are regular (e.g., monthly) or irregular, as all these will determine different t.register usage possibilities.\nHere, we will exemplify the use of a list of maps and, since our data represent regular time intervals, we will use the start and increment options together with the i flag to actually create the intervals.\n\n# Get list of maps and print the first 5 elements \nmap_list = gs.list_grouped(type=\"raster\", pattern=\"lst_201*\")['italy_LST_daily']\nmap_list[0:6]\n\n\n# How many maps do we have?\nlen(map_list)\n\n\n# Register maps in strds  \ngs.run_command(\"t.register\", \n               input=\"lst_daily\",\n               maps=map_list,\n               increment=\"1 days\",\n               start=\"2014-01-01\", \n               flags=\"i\")\n\nLet’s check the metadata once again, all fields should be populated now.\n\n# Get info about the strds\nprint(gs.read_command(\"t.info\",\n                      input=\"lst_daily\",\n                      flags=\"g\"))\n\nThe tool t.info can also provide information of single maps, e.g.:\n\n# Get info about a map within the strds\ngs.run_command(\"t.info\", \n               input=\"lst_2014.005_avg\", \n               type=\"raster\")\n\n\n\n\n\n\n\nNote\n\n\n\nCompare with the output of r.info map=lst_2014.005_avg.\n\n\n\nDifferent ways of registering maps\nAccording to the data you are working with, there might be different options to properly register the data within time series objects. The case presented above is one of the easiest, i.e., data represents regular intervals. So, start, increment and i did it.\nLet’s suppose however, we now work with the so called 8-day or 16-day products. These also represent interval time, but the last map of each year has a different granularity. This is because the aggregation cycle restarts every January 1st, and also because we have leap years. In this case, the option increment=\"8 days\" will give wrong results. The solution is to create a text file containing map name, start and end time, and pass it with the file option.\nLuckily, this can be done programmatically. Indeed, most data file names come with some indication of date that we can use to create our file. See for example this small python script or the shell example within t.rast.aggregate.ds manual. Furthermore, tools such as i.modis.import will create the registration file for you after importing products into GRASS GIS.\nA similar case occurs when handling imagery data. Usually, they represent time instances (not intervals, i.e., no end date). Hence, to register imagery data, we might also need to create a text file. In this case, with map names and start time only. Tools like i.sentinel.import or i.landsat.import can create this file for you when you import data into GRASS GIS.\n\n\n\n\n\n\nNote\n\n\n\nHave a look at the t.register manual page and a dedicated wiki with further examples.\n\n\n\n\n\nTime series visualization\nThere are different tools for time series visualization in GRASS GIS. In this tutorial, we will explore those within the Graphical User Interface.\n\nTimeline plot\nThe timeline plot, g.gui.timeline, is a graphic visualization of the temporal and (optionally) spatial granularity and extent of a STDS. It is very useful to compare granularities and observe topological relationships among STDS.\n\n!g.gui.timeline inputs=lst_daily\n\n\n\n\ng.gui.timeline output\n\n\n\n\nTemporal plot for Trento, Italy\nThe temporal plot tool, g.gui.tplot, allows to plot the time series values of raster or vector space-time datasets. In this case, we will plot the LST time series for the city of Trento, Italy. In the graphical interface of g.gui.tplot, the point coordinates can be typed directly, copied from the map or selected interactively in the map display.\n\n# LST time series plot for Trento city center\n!g.gui.tplot strds=lst_daily coordinates=4410837.455830389,2559852.473498233 title=\"Trento daily LST\" xlabel=\"Time\" ylabel=\"LST (C)\" size=800,500 output=trento.png \n\n\n\n\ng.gui.tplot output\n\n\nIf instead you want to query and plot time series of several points in a vector map, you might want to check t.rast.what.\n\ngs.run_command(\"v.random\", \n               output=\"random_points\",\n               npoints=5,\n               seed=54)\ngs.run_command(\"t.rast.what\",\n               points=\"random_points\",\n               strds=\"lst_daily\",\n               where=\"start_time &gt;= '2018-09-30'\",\n               layout=\"col\",\n               flags=\"n\")\n\n\n\n\nLists and filtering\nThere are different tools dedicated to listing within the temporal framework:\n\nt.list to list STDS and maps registered within the temporal database whether they belong to a STDS or not,\nt.rast.list for maps in raster time series, and\nt.vect.list for maps in vector time series.\n\nThe variables that can be used to perform listing and filtering differ among raster and vector time series:\n\nSTRDS: id, name, creator, mapset, temporal_type, creation_time, start_time, end_time, north, south, west, east, nsres, ewres, cols, rows, number_of_cells, min, max.\nSTVDS: id, name, layer, creator, mapset, temporal_type, creation_time, start_time, end_time, north, south, west, east, points, lines, boundaries, centroids, faces, kernels, primitives, nodes, areas, islands, holes, volumes.\n\nLet’s see some listing examples:\n\n# Check list of STRDS in the mapset\nprint(gs.read_command(\"t.list\", \n                      type=\"strds\"))\n\n\n# Check raster maps in the temporal database\nprint(gs.read_command(\"t.list\", \n                      type=\"raster\",\n                      where=\"start_time &gt;= '2018-06-30'\"))\n\nWith the Python Pandas package we can simply read in the output of t.rast.list as a DataFrame:\n\nimport pandas as pd\n\n# Check the list of maps in the STRDS\npd.DataFrame(gs.parse_command(\"t.rast.list\", input=\"lst_daily\", format=\"csv\"))\n\n\n# Check min and max per map\npd.DataFrame(gs.parse_command(\"t.rast.list\",\n                              input=\"lst_daily\",\n                              columns=\"name,min,max\",\n                              format=\"csv\"))\n\n\n# Maps with minimum value lower than or equal to 10\npd.DataFrame(gs.parse_command(\"t.rast.list\",\n                              input=\"lst_daily\",\n                              order=\"min\", \n                              columns=\"name,start_time,min\",\n                              where=\"min &lt;= '10.0'\",\n                              format=\"csv\"))\n\n\n# Maps with maximum value higher than 30\npd.DataFrame(gs.parse_command(\"t.rast.list\",\n                              input=\"lst_daily\",\n                              order=\"max\",\n                              columns=\"name,start_time,max\",\n                              where=\"max &gt; '30.0'\",\n                              format=\"csv\"))\n\n\n# Maps between two given dates\npd.DataFrame(gs.parse_command(\"t.rast.list\",\n                              input=\"lst_daily\",\n                              columns=\"name,start_time\",\n                              where=\"start_time &gt;= '2015-05' and start_time &lt;= '2015-08-01 00:00:00'\",\n                              format=\"csv\"))\n\n\n# Maps from January\npd.DataFrame(gs.parse_command(\"t.rast.list\",\n                              input=\"lst_daily\",\n                              columns=\"name,start_time\",\n                              where=\"strftime('%m', start_time)='01'\",\n                              format=\"csv\"))\n\nMost tools within the temporal framework have the where option. So, the same filtering can be applied in tools to determine maps that will be processed.\n\n\nDescriptive statistics\nThe tool t.rast.univar calculates univariate statistics from the non-null cells of each raster map within STRDS. By default it returns the name of the map, the start and end date of the dataset and the following values: mean, minimum and maximum value, mean_of_abs, standard deviation, variance, coeff_var, number of null cells, total number of cells.\n\n# Print univariate stats for maps within STRDS\nprint(gs.read_command(\"t.rast.univar\",\n                      input=\"lst_daily\",\n                      nprocs=6))\n\nUsing the e flag it can calculate also extended statistics and the output can be saved in a text file to be read elsewhere.\n\n# Write extended univariate stats output to a csv file\ngs.run_command(\"t.rast.univar\",\n               flags=\"e\",\n               input=\"lst_daily\",\n               output=\"ext_stats_lst_daily.csv\",\n               separator=\"comma\",\n               nprocs=6)\n\nThe Python pandas package allows us to read this file and then make plots.\n\n# Read the csv and plot\nlst = pd.read_csv(\"ext_stats_lst_daily.csv\", usecols=[2, 4, 5, 6])\nlst['start'] = pd.to_datetime(lst.start, format=\"%Y-%m-%d\", exact=False)\nlst\n\nLet’s have a look at the plot:\n\nlst.plot.line(0, [1,2,3], subplots=False);"
  },
  {
    "objectID": "time_series/time_series_management_and_visualization.html#references",
    "href": "time_series/time_series_management_and_visualization.html#references",
    "title": "Time series management and visualization",
    "section": "References",
    "text": "References\n\nMetz, M., Andreo, V., Neteler, M. 2017. A New Fully Gap-Free Time Series of Land Surface Temperature from MODIS LST Data. Remote Sensing 9(12), 1333. DOI.\nGebbert, S., Pebesma, E. 2014. TGRASS: A temporal GIS for field based environmental modeling. Environmental Modelling & Software 53, 1-12. DOI.\nGebbert, S., Pebesma, E. 2017. The GRASS GIS temporal framework. International Journal of Geographical Information Science 31, 1273-1292. DOI.\nTemporal data processing wiki page.\n\n\n\nThe development of this tutorial was funded by the US National Science Foundation (NSF), award 2303651."
  },
  {
    "objectID": "time_series/time_series_extraction.html",
    "href": "time_series/time_series_extraction.html",
    "title": "Time series: Subset, import and export",
    "section": "",
    "text": "In this seventh part of the time series tutorials, we will go through time series subset, import and export."
  },
  {
    "objectID": "time_series/time_series_extraction.html#subset",
    "href": "time_series/time_series_extraction.html#subset",
    "title": "Time series: Subset, import and export",
    "section": "Subset",
    "text": "Subset\nFor extracting a subset from a strds, we use t.rast.extract. The subset is based on temporal variables like start_time, start_doy, end_week, etc. This tool outputs a new strds and offers the possibility to apply a mapcalc operation on the fly. If no r.mapcalc expression is defined, the selected maps are simply registered in the new created output strds to avoid data duplication.\nLet’s see a couple of examples. Suppose we are only interested in summer months, i.e., June, July, August. The maps matching the where condition will be\nregistered in the new output strds.\n\ngs.run_command(\"t.rast.extract\",\n               input=\"lst_daily\",\n               output=\"lst_daily_summer\",\n               where=\"strftime('%m',start_time)='06' or strftime('%m',start_time)='07' or strftime('%m', start_time)='08'\")\n\nIf you remember, we went through several listing examples in the “Time series management and visualization” tutorial.  A way of checking the subset will actually give us what we want, is running t.rast.list with the same where condition than above.\n\ngs.run_command(\"t.rast.list\",\n               input=\"lst_daily_summer\",\n               columns=\"name,min,max\")\n\nTo check whether a map is registered in different stds, we can use t.info.\n\ngs.run_command(\"t.info\",\n               input=\"lst_2018.243_avg\",\n               type=\"raster\")\n\nLet’s see now an example including a mapcalc operation. We still want the daily maps of summer, but we are only interested in areas where LST was higher than 25 degrees. Note that in this second case, we created a new strds, i.e., we modified the original with the mapcalc expression, so we need to provide basename and suffix for the newly created maps.\n\ngs.run_command(\"t.rast.extract\",\n               input=\"lst_daily\",\n               output=\"lst_daily_summer_higher_25\",\n               basename=\"lst_daily\",\n               suffix=\"gran\",\n               where=\"strftime('%m',start_time)='06' or strftime('%m',start_time)='07' or strftime('%m', start_time)='08'\",\n               expression=\"if(lst_daily &lt; 25.0, null(), lst_daily)\")\n\nCheck that min value of all extracted maps are actually above 25 degrees.\n\ngs.run_command(\"t.rast.list\",\n               input=\"lst_daily_summer_higher_25\",\n               columns=\"name,min,max\")\n\nWhat tools would you use now if you wanted to know how many summer days had temperatures above 25 degrees each year and how does the maximum number of days with LST &gt; 25 varies regionally?\nSmall hint? Go back to the time series aggregation tutorial.\n\n# Get number of summer days with LST &gt; 25 per year\ngs.run_command(\"t.rast.aggregate\",\n              input=\"lst_daily_summer_higher_25\",\n              output=\"count_lst_daily_summer_higher_25\",\n              basename=\"count_lst_daily_summer_higher_25\",\n              suffix=\"gran\",\n              method=\"count\",\n              granularity=\"1 year\")\n\n\n# Get maximum number of days with LST &gt; 25\ngs.run_command(\"t.rast.series\",\n              input=\"count_lst_daily_summer_higher_25\",\n              output=\"max_count_summer_days_lst_higher_25\",\n              method=\"maximum\")\n\n\n# Mask zero values\ngs.run_command(\"r.mask\", \n               raster=\"max_count_summer_days_lst_higher_25\",\n               maskcats=0,\n               flags=\"i\")\n\n\n# Visualize the result\nmax_count = gj.InteractiveMap(width = 500, use_region=True, tiles=\"CartoDB.DarkMatter\")\nmax_count.add_raster(\"max_count_summer_days_lst_higher_25\")\nmax_count.add_layer_control(position = \"bottomright\")\nmax_count.show()"
  },
  {
    "objectID": "time_series/time_series_extraction.html#export",
    "href": "time_series/time_series_extraction.html#export",
    "title": "Time series: Subset, import and export",
    "section": "Export",
    "text": "Export\nThere are three tools to export raster time series in different formats.\n\nt.rast.export exports a strds as a tar archive containing raster maps either as GeoTIFF or GRASS binary files and several metadata files such as: timestamps, CRS info, strds and raster info. The archive can be compressed with gzip or bzip2. The output of t.rast.export can then be imported with t.rast.import.\nt.rast.out.vtk exports a strds as a VTK file to be visualized with any VTK visualizer.\nt.rast.out.xyz exports a strds to a CSV file of the form x coord, y coord, value.\n\nLet’s see some examples.\n\n# Export strds as an archive\ngs.run_command(\"t.rast.export\", \n               input=\"lst_daily_summer\", \n               output=\"lst_daily_summer_2014.tar.bzip2\",\n               where=\"start_time &lt; '2015-01-01'\")\n\n\n!tar xvjf lst_daily_summer_2014.tar.bzip2\n\nlst_2014.152_avg.tif\nlst_2014.152_avg.color\n...\nlst_2014.243_avg.tif\nlst_2014.243_avg.color\nlist.txt\nproj.txt\ninit.txt\nreadme.txt\nmetadata.txt\n\n# Export strds as VTK\ngs.run_command(\"t.rast.out.vtk\",\n              input=\"count_lst_daily_summer_higher_25\",\n              directory=\"/tmp\",\n              elevation=\"elevation\")\n\nThe tool t.rast.out.xyz is an addon, so we first need to install it with g.extension.\n\n# Install extension\ngs.run_command(\"g.extension\",\n               extension=\"t.rast.out.xyz\")\n\n\n# Export strds as xyz CSV file\ngs.run_command(\"t.rast.out.xyz\",\n               strds=\"count_lst_daily_summer_higher_25\",\n               output=\"count_lst_daily_summer_higher_25.csv\")\n\n\n!head count_lst_daily_summer_higher_25.csv"
  },
  {
    "objectID": "time_series/time_series_extraction.html#import",
    "href": "time_series/time_series_extraction.html#import",
    "title": "Time series: Subset, import and export",
    "section": "Import",
    "text": "Import\nThere are two tools to import raster time series into GRASS GIS: * t.rast.import imports strds that were exported with t.rast.export. It allows to create a new GRASS project with the imported data CRS and set the computational region to the raster maps imported. * t.rast.import.netcdf imports the content of one or more netCDF files that adhere to the CF convention into a strds. Data can be imported or linked via r.external.\nLet’s see an example with t.rast.import.\n\n# Import the exported strds into a new GRASS project\ngs.run_command(\"t.rast.import\",\n               input=\"lst_daily_summer_2014.tar.bzip2\",\n               output=\"lst_daily_summer_new\",\n               title=\"Daily summer LST\",\n               description=\"Daily summer LST for 2014\")\n\n\n# Check the new strds was created\ngs.run_command(\"t.list\", where=\"NAME LIKE '%summer%'\")\n\n\n\n\n\n\n\nWhat about vector time series?\n\n\n\nWhile not covered in this tutorial, there are also dedicated tools for subsetting, importing and exporting vector time series objects. These are:\n\nt.vect.extract\nt.vect.export\nt.vect.import"
  },
  {
    "objectID": "time_series/time_series_extraction.html#references",
    "href": "time_series/time_series_extraction.html#references",
    "title": "Time series: Subset, import and export",
    "section": "References",
    "text": "References\n\nGebbert, S., Pebesma, E. 2014. TGRASS: A temporal GIS for field based environmental modeling. Environmental Modelling & Software 53, 1-12. DOI.\nGebbert, S., Pebesma, E. 2017. The GRASS GIS temporal framework. International Journal of Geographical Information Science 31, 1273-1292. DOI.\nTemporal data processing wiki page.\n\n\n\nThe development of this tutorial was funded by the US National Science Foundation (NSF), award 2303651."
  },
  {
    "objectID": "time_series/time_series_aggregations.html",
    "href": "time_series/time_series_aggregations.html",
    "title": "Time series aggregation",
    "section": "",
    "text": "In this second part of the time series tutorials, we will go through different ways of performing aggregations. Temporal aggregation is a very common task when working with time series as it allows us to summarize information and find patterns of change both in space and time.\nThere are two main tools to do time series aggregations in GRASS GIS: t.rast.aggregate and t.rast.series. We’ll demonstrate their usage in the upcoming sections."
  },
  {
    "objectID": "time_series/time_series_aggregations.html#aggregation-with-granularity",
    "href": "time_series/time_series_aggregations.html#aggregation-with-granularity",
    "title": "Time series aggregation",
    "section": "Aggregation with granularity",
    "text": "Aggregation with granularity\nGranularity is the greatest common divisor of the temporal extents (and possible gaps) of all maps in a space-time dataset. To perform time series aggregation with granularity, we use t.rast.aggregate. This tool allows us to aggregate our time series into larger granularities, i.e., from hourly to daily, from daily to weekly, monthly, etc. It also permits to aggregate with ad hoc granularities like 3 minutes, 5 days, 3 months, etc. Supported aggregate methods include average, minimum, maximum, median, etc. See the r.series manual page for details.\nIf you are working with data representing absolute time, t.rast.aggregate will shift the start date for each aggregation process depending on the provided temporal granularity as follows:\n\nyears: will start at the first of January, hence 14-08-2012 00:01:30 will be shifted to 01-01-2012 00:00:00\nmonths: will start at the first day of a month, hence 14-08-2012 will be shifted to 01-08-2012 00:00:00\nweeks: will start at the first day of a week (Monday), hence 14-08-2012 01:30:30 will be shifted to 13-08-2012 01:00:00\ndays: will start at the first hour of a day, hence 14-08-2012 00:01:30 will be shifted to 14-08-2012 00:00:00\nhours: will start at the first minute of a hour, hence 14-08-2012 01:30:30 will be shifted to 14-08-2012 01:00:00\nminutes: will start at the first second of a minute, hence 14-08-2012 01:30:30 will be shifted to 14-08-2012 01:30:00\n\nThe specification of the temporal relation between the aggregation intervals and the raster map layers to be aggregated is always formulated from the aggregation interval viewpoint. By default, it is set to contains to aggregate all maps that are temporally located in an aggregation interval.\n\nMonthly and seasonal averages\nTo demonstrate the basic usage of t.rast.aggregate, let’s create monthly and seasonal time series starting from the lst_daily time series we created in the time series management tutorial.\n\n# Daily to monthly\ngs.run_command(\"t.rast.aggregate\",\n                input=\"lst_daily\",\n                method=\"average\",\n                granularity=\"1 months\",\n                basename=\"lst_avg\",\n                output=\"lst_monthly\",\n                suffix=\"gran\",\n                nprocs=4)\n\n\n# Daily to (sort of) seasonal\ngs.run_command(\"t.rast.aggregate\",\n                input=\"lst_daily\",\n                method=\"average\",\n                granularity=\"3 months\", \n                basename=\"lst_avg\", \n                output=\"lst_seasonal\", \n                suffix=\"gran\",\n                nprocs=4)\n\nIf we would like to follow the so called meteorological seasons, i.e., that spring started with March, then we could have used the where option to shift the starting point of the aggregation period as follows: where=\"start_time &gt;= '2013-03-01 00:00:00'\".\nLet’s compare the granularities using the timeline plot…\n\n!g.gui.timeline lst_monthly,lst_seasonal\n\n\nand use grass.jupyter to create a nice animation of the seasonal time series:\n\nlstseries = gj.TimeSeriesMap(use_region=True)\nlstseries.add_raster_series(\"lst_seasonal\", fill_gaps=False)\nlstseries.d_legend(color=\"black\", at=(10,40,2,6))\nlstseries.show()\n\n\n# Optionally, write out to animated GIF\nlstseries.save(\"lstseries.gif\")\n\nFor astronomical seasons, i.e., those defined by solstices and equinoxes, we can use t.rast.aggregate.ds as in this example, or for an approximate result:\n\ngs.run_command(\"t.rast.aggregate\",\n                input=\"lst_daily\",\n                method=\"average\",\n                where=\"start_time &gt;= '2013-03-21 00:00:00'\",\n                granularity=\"3 months\", \n                basename=\"lst_avg\", \n                output=\"lst_seasonal\", \n                suffix=\"gran\",\n                nprocs=4)\n\n\n# Check info\ngs.read_command(\"t.info\",\n                input=\"lst_seasonal\",\n                flags=\"g\")\n\n\n# Check raster maps in the STRDS\ngs.run_command(\"t.rast.list\", input=\"lst_seasonal\")\n\n\n\n\n\n\n\nTip\n\n\n\nThere’s an upcoming addon that will perform seasonal aggregations. See: https://github.com/OSGeo/grass-addons/pull/1010.\n\n\n\n\nSpring warming\nWe define spring warming as the velocity with which temperature increases from winter into spring and we can approximate it as the linear regression slope among LST values of February, March and April. Let’s see how to use t.rast.aggregate to estimate yearly spring warming values.\n\n# Define list of months\nmonths=['{0:02d}'.format(m) for m in range(2,5)]\nprint(months)\n\n\n# Annual spring warming\ngs.run_command(\"t.rast.aggregate\",\n               input=\"lst_daily\",\n               output=\"annual_spring_warming\",\n               basename=\"spring_warming\",\n               suffix=\"gran\",\n               method=\"slope\",\n               granularity=\"1 years\",\n               where=f\"strftime('%m',start_time)='{months[0]}' or strftime('%m',start_time)='{months[1]}' or strftime('%m', start_time)='{months[2]}'\")\n\n\n# Check raster maps in the STRDS\ngs.run_command(\"t.rast.list\", input=\"annual_spring_warming\")\n\n\nspring_warming = gj.TimeSeriesMap(use_region=True)\nspring_warming.add_raster_series(\"annual_spring_warming\", fill_gaps=False)\nspring_warming.d_legend(color=\"black\", at=(10,40,2,6))\nspring_warming.show()\n\n\n\n\n\n\n\nQuestion\n\n\n\n\n\nHow would you obtain the average spring warming over the whole time series?\n\n# Average spring warming\ngs.run_command(\"t.rast.series\",\n               input=\"annual_spring_warming\",\n               output=\"avg_spring_warming\",\n               method=\"average\")\n               \n# Display raster map with interactive class\nspw_map = gj.InteractiveMap(width = 500, use_region=True, tiles=\"CartoDark\")\nspw_map.add_raster(\"avg_spring_warming\")\nspw_map.add_layer_control(position = \"bottomright\")\nspw_map.show()"
  },
  {
    "objectID": "time_series/time_series_aggregations.html#full-series-aggregation",
    "href": "time_series/time_series_aggregations.html#full-series-aggregation",
    "title": "Time series aggregation",
    "section": "Full series aggregation",
    "text": "Full series aggregation\nThe previous question (as you might have seen) can be solved using t.rast.series. This tool allows us to aggregate complete time series (or only selected parts) with a certain method. Available aggregation methods include average, minimum, maximum, median, etc. See the r.series manual page for details.\n\nMaximum and minimum LST\nWe’ll demonstrate how to aggregate the whole lst_daily time series to obtain the maximum and minimum LST value for the period 2014-2018. Note that the input is a STRDS object while the output is a single map in which pixel values correspond to the maximum or minimum value of the time series they represent.\n\n# Get maximum and minimum LST in the STRDS\nmethods=[\"maximum\",\"minimum\"]\n\nfor m in methods:\n    gs.run_command(\"t.rast.series\",\n                   input=\"lst_daily\",\n                   output=f\"lst_{m}\",\n                   method=m,\n                   nprocs=4)\n\n\n# Change color palette to Celsius\ngs.run_command(\"r.colors\",\n               map=\"lst_minimum,lst_maximum\",\n               color=\"celsius\")\n\nLet’s use the InteractiveMap class from grass.jupyter to visualize the maximum and minimum LST maps.\n\n# Plot\nlst_map=gj.InteractiveMap(width = 500)\nlst_map.add_raster(\"lst_minimum\")\nlst_map.add_raster(\"lst_maximum\")\nlst_map.add_layer_control(position = \"bottomright\")\nlst_map.show()\n\n\n\nLong term aggregations\nIf we want to know how is the temperature on a “typical” January, February and so on, we estimate the so called long-term averages or climatologies for each month. These are usually computed over 20 or 30 years of data, but for the purpose of demonstrating the usage of t.rast.series, we will use our 5-year time series here.\nWe will use something we learnt in the listing and selection examples in the first time series tutorial, i.e., we need to select all maps for each month to perform the aggregation. So, the input will be the whole time series, but we will use only some maps to estimate the long term monthly average, minimum and maximum values. Let’s see how to do all that with a simple for cycle looping over months and methods:\n\n# Estimate long term aggr for all months and methods\nmonths=['{0:02d}'.format(m) for m in range(1,13)]\nmethods=[\"average\",\"minimum\",\"maximum\"]\n\nfor m in months:\n    for me in methods:\n        print(f\"Aggregating all {m} maps with {me} method\")\n        gs.run_command(\"t.rast.series\", \n                       input=\"lst_daily\",\n                       method=me,\n                       where=f\"strftime('%m', start_time)='{m}'\",\n                       output=\"lst_{}_{}\".format(me,m))\n\n\n# List newly created maps\nmap_list = gs.list_grouped(type=\"raster\", \n                           pattern=\"*{average,minimum,maximum}*\")['italy_LST_daily']\nprint(map_list)\n\nLet’s create an animation of the long term average LST.\n\n# List of average maps\nmap_list = gs.list_grouped(type=\"raster\", pattern=\"*average*\")['italy_LST_daily']\n\n# Animation with SeriesMap class\nseries = gj.SeriesMap(height = 500)\nseries.add_rasters(map_list)\nseries.d_barscale()\nseries.show()\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhy didn’t we list with t.rast.list?\n\n\n\n\nBioclimatic variables\nPerhaps you have heard of Worldclim or CHELSA bioclimatic variables? Well, these are 19 variables that represent potentially limiting conditions for species. They derive from the combination of temperature and precipitation long term aggregations. Let’s use those that we estimated in the previous example to estimate the bioclimatic variables that include temperature. GRASS GIS has a very nice extension, r.bioclim, to estimate bioclimatic variables.\n\n# Install extension\ngs.run_command(\"g.extension\",\n               extension=\"r.bioclim\")\n\n\n# Get lists of maps needed\ntmin=gs.list_grouped(type=\"raster\", pattern=\"lst_minimum_??\")[\"italy_LST_daily\"]\ntmax=gs.list_grouped(type=\"raster\", pattern=\"lst_maximum_??\")[\"italy_LST_daily\"]\ntavg=gs.list_grouped(type=\"raster\", pattern=\"lst_average_??\")[\"italy_LST_daily\"]\n\nprint(tmin,tmax,tavg)\n\n\n# Estimate temperature related bioclimatic variables\ngs.run_command(\"r.bioclim\", \n               tmin=tmin, \n               tmax=tmax,\n               tavg=tavg, \n               output=\"worldclim_\") \n\n\n# List output maps\ngs.list_grouped(type=\"raster\", pattern=\"worldclim*\")[\"italy_LST_daily\"]\n\nLet’s have a look at some of the maps we just created\n\n# Display raster map with interactive class\nbio_map = gj.InteractiveMap(width = 500, use_region=True)\nbio_map.add_raster(\"worldclim_bio01\")\nbio_map.add_raster(\"worldclim_bio02\")\nbio_map.add_layer_control(position = \"bottomright\")\nbio_map.show()\n\nLet’s assume a certain insect species can only survive where winter mean temperatures are above 5 degrees. How would you determine suitable areas? We’ll see that in the upcoming tutorial, stay tuned!\n\n\n\n\n\n\nTip\n\n\n\nIf you are curious, maybe you want to have a look at t.rast.mapcalc and t.rast.algebra."
  },
  {
    "objectID": "time_series/time_series_aggregations.html#references",
    "href": "time_series/time_series_aggregations.html#references",
    "title": "Time series aggregation",
    "section": "References",
    "text": "References\n\nGebbert, S., Pebesma, E. 2014. TGRASS: A temporal GIS for field based environmental modeling. Environmental Modelling & Software 53, 1-12. DOI.\nGebbert, S., Pebesma, E. 2017. The GRASS GIS temporal framework. International Journal of Geographical Information Science 31, 1273-1292. DOI.\nTemporal data processing wiki page.\n\n\n\nThe development of this tutorial was funded by the US National Science Foundation (NSF), award 2303651."
  },
  {
    "objectID": "fast_track_grass_and_python.html",
    "href": "fast_track_grass_and_python.html",
    "title": "Fast track to GRASS & Python in Jupyter Notebooks",
    "section": "",
    "text": "Python, a widely used general-purpose, high-level programming language provides a powerful scripting interface for geospatial data processing. Being easy-to-use yet powerful, it enables users to efficiently exploit the capabilities of the GRASS GIS software. Python scripts for GRASS GIS can be written at high level (GRASS GIS modules) as well as at low level (GRASS GIS libraries) through dedicated interfaces. Indeed, GRASS GIS is distributed with a set of python packages to provide functionalities at different levels.\nIn this tutorial, we willl focus on two of such packages: grass.script and grass.jupyter, which provide Python interface to launch GRASS GIS modules in scripts and offer classes and setup functions for running GRASS GIS in Jupyter Notebooks, respectively. We will exemplify two different use cases:\nLet’s first go through the main functions of GRASS GIS Python packages."
  },
  {
    "objectID": "fast_track_grass_and_python.html#lets-get-started",
    "href": "fast_track_grass_and_python.html#lets-get-started",
    "title": "Fast track to GRASS & Python in Jupyter Notebooks",
    "section": "Let’s get started!",
    "text": "Let’s get started!\n\nSetup\nThis tutorial can be run locally. You need to have GRASS GIS 8.4+ and Jupyter installed. For part A, please download these Sentinel 2 scenes and move the unzipped download into the directory where you are running this tutorial. For part B, we asume that you have downloaded the North Carolina sample dataset, i.e., there’s an existing GRASS project. Be sure you also have the following Python libraries installed in your environment: folium, numpy, seaborn, matplotlib, pandas.\nThe first thing we need to do for any of the cases we’ll see further on, is to import GRASS GIS python packages. In order to do so, we need to add GRASS GIS python package to PATH. Let’s see how we do that.\n\n# import standard Python packages\nimport os\nimport sys\nimport subprocess\nfrom pathlib import Path\n\n\n# check where GRASS GIS python packages are and add them to PATH\nsys.path.append(\n    subprocess.check_output([\"grass-dev\", \"--config\", \"python_path\"], text=True).strip()\n)\n\n\n# import GRASS GIS python packages\nimport grass.script as gs\nimport grass.jupyter as gj\n\n\n\nA. Use GRASS GIS tools within your Python spatial workflows\nNow, let’s assume you have some raster data you want to process with GRASS GIS tools, eg. Sentinel 2 satellite data, to obtain texture indices. The first thing you’ll need to do is to create a GRASS GIS project to import your data. As we saw already in a previous fast track tutorial, GRASS projects are folders where we store spatial data with the same spatial reference. These projects can be placed wherever you want, including a temporary directory if you are mostly interested in the outputs only.\nSo, let’s create a project in a temporary directory to import, i.e. read, our data with GRASS GIS. The gs.create_project() function allows us to create a GRASS project passing different information. For example, we can use the EPSG code of the data CRS or directly pass a georeferenced file.\n\n# Create a temporary folder where to place our GRASS project\nimport tempfile\ntempdir = tempfile.TemporaryDirectory()\n\n\n# Create a project in the temporary directory\ngs.create_project(path=tempdir.name, \n                  name=\"nc_sentinel\", \n                  epsg=\"32617\", \n                  overwrite=True)\n\nAlternatively, use a georeferenced file to read the spatial reference information from:\n\n# gs.create_project(path=tempdir.name, name=\"nc_sentinel\", filename=\"path/to/georef/file\", overwrite=True)\n\nAny of the commands above will create a GRASS project within your working directory, i.e., where you are running the notebook in this case. If you want to create the project somewhere else, you need to use the path parameter.\nNow that we created a project, let’s start a GRASS GIS session there.\n\n# Start GRASS in the recently created project\nsession = gj.init(Path(tempdir.name,\"nc_sentinel\"))\n\nWe are now ready to import data into the recently created project. Let’s use a for loop to import all 10 m resolution bands. These are level 2A surface reflectance data for blue, green, red and near infrared Sentinel 2 bands.\n\nfiles = sorted(Path('./nc_sentinel_utm17n/S2A_MSIL2A_20220304T160151_N0400_R097_T17SQV_20220304T215812.SAFE/GRANULE/L2A_T17SQV_A034986_20220304T160221/IMG_DATA/R10m').glob('*B*.jp2'))\nfiles\n\n\nfor file in files:\n    name = str(file)[-11:-4]\n    print(\"importing \" + name)\n    gs.run_command(\"r.import\", input=file, output=name)\n\nLet’s check the files we just imported are there:\n\ngs.list_grouped(type=\"raster\")[\"PERMANENT\"]\n\nLet’s have a quick look to one of the imported bands. We can use the InteractiveMap class from the grass.jupyter package to visualize.\n\nm = gj.InteractiveMap(width=\"500\", tiles=\"OpenStreetMap\")\nm.add_raster(\"B08_10m\")\nm.add_layer_control()\nm.show()\n\nNext step would be to do some processing or analysis with the imported data. It is somehow common to estimate texture measures over pancromatic bands. Since we do not have one in Sentinel 2 data, we’ll create a synthetic one by averaging blue, green and red bands. Since, we’ll be creating new raster maps, we first need to set our computational region to the extent and resolution of one of our imported bands, and while there we’ll remove the sawed edges from our maps.\n\n# Set computational region\ngs.run_command(\"g.region\", raster=\"B08_10m\", grow=-40, flags=\"p\")\n\n\nm = gj.InteractiveMap(width=\"500\", tiles=\"OpenStreetMap\", use_region=True)\nm.add_raster(\"B08_10m\")\nm.add_layer_control()\nm.show()\n\n\n# Create synthetic pan band\ngs.mapcalc(exp=\"pan = (B02_10m + B03_10m + B04_10m) / 3\")\n\nNow that we have the synthetic pan band, let’s estimate some texture measures with the r.texture tool.\n\ngs.run_command(\"r.texture\", \n              input=\"pan\", \n              output=\"pan\", \n              size=5, \n              method=\"contrast,corr\")\n\n\ngs.list_grouped(type=\"raster\", pattern=\"pan*\")\n\n\nt = gj.InteractiveMap(width=\"500\", tiles=\"OpenStreetMap\", use_region=True)\nt.add_raster(\"pan_Contr\")\nt.add_raster(\"pan_Corr\")\nt.add_layer_control()\nt.show()\n\nFinally, we can export our texture maps out of GRASS GIS and use them somewhere else or load them into a webGIS.\n\ntexture_maps = gs.list_grouped(type=\"raster\", pattern=\"pan_*\")[\"PERMANENT\"]\ntexture_maps\n\n\nfor i in texture_maps:\n    gs.run_command(\"r.out.gdal\", input=i, output=f\"{i}.tif\", format=\"GTiff\")\n\nAs you might see this use case somehow follows/is compatible with the Extract-Transform-Load (ETL) process common in production systems. Indeed, this approach allows to include GRASS GIS tools into such workflows. These type of tasks could be automatized in scripts to be run without even starting GRASS GIS using the --exec tool… but that’s material for a different tutorial :)\n\n\nB. Use Python tools within GRASS GIS workflows\nThis case is more focused towards GRASS users that want to combine GRASS GIS with other Python tools for their data processing and analysis workflows.\nSeveral GRASS users store most or all of their projects in a single folder, which has traditionally been called grassdata. When this is the case, to start GRASS GIS in an existing project, we also need to provide the path to such a folder.\n\n# GRASS GIS variables\nhomedir = os.path.expanduser('~')\ngrassdata = os.path.join(homedir, \"grassdata\")\nproject = \"nc_basic_spm_grass7\"\nmapset = \"PERMANENT\"\n\n\n# Start GRASS\nsession = gj.init(grassdata, project, mapset)\n\nWe are now within a GRASS project, let’s obtain information about it, like CRS details, region settings, list of raster and vector maps, etc.\n\n# Print project's CRS\ngs.parse_command(\"g.proj\", flags=\"g\")[\"srid\"]\n\n\n# Print computational region\ngs.region()\n\n\n# List raster maps\ngs.list_grouped([\"raster\"])\n\nLet’s obtain metadata about the elevation raster map.\n\n# Raster info\ngs.raster_info(\"elevation\")\n\nIf we would only need to know or use the minimum value of the elevation raster, we can get it as follows:\n\ngs.raster_info(\"elevation\")[\"min\"]\n\nLet’s now visualize raster and vector maps with a different grass.jupyter class, the non-interactive Map class. This class creates and displays GRASS maps as PNG files. We basically instantiate the class first, add maps and maps’ elements and finally show the result. There are 2 ways of calling display (d.*) modules:\n\nreplace . by _ as in m.d_rast()\nuse run() as in m.run(\"d.rast\")\n\n\n# Instantiate the Map class\nm = gj.Map(width=400)\n\nThe Map class will by default use the first raster or vector extent to set the display extent. You could however also use the current computational region with use_region=True or call a previously saved computational region (different than the current) with the argument saved_region.\n\n# Add maps and map elements\nm.d_rast(map=\"elevation\")\nm.d_vect(map=\"streams\")\nm.d_legend(raster=\"elevation\", at=(60, 95, 85, 90), flags=\"b\")\n\n\n# Disply the result\nm.show()\n\nWe can save our displayed maps by calling the save() method, i.e., m.save(). For the Map class it will output a PNG file, while for the InteractiveMap class an HTML.\nLet’s now see how to convert our GRASS rasters into numpy arrays. Having our raster maps as numpy arrays opens up a world of possibilities in terms of visualization and data analysis and modelling. We won’t go into anything complex here, but we’ll show how to read rasters into numpy arrays, plot them, modify them and then write them back into GRASS.\n\n# Import required libraries\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom grass.script import array as garray\n\n\n# Read elevation as numpy array\nelev = garray.array(mapname=\"elevation\", null=\"nan\")\nprint(elev.shape)\n\n\n# Estimate array average\nprint(np.average(elev))\n\n\n# Plot elev histogram\nsns.set_style('darkgrid')\nsns.histplot(data=elev.ravel(), kde=True)\nplt.show()\n\nLet’s modify our array and write it back into GRASS GIS. For this, we create a new copy of the GRASS elevation map first as shown below.\n\nelev_2 = garray.array(mapname=\"elevation\")\nelev_2 *= 2\n\n\n# Plot elev*2\nsns.histplot(data=elev_2.ravel(), kde=True)\n\nNow we write the modified array into a GRASS raster map and check it’s actually there.\n\nelev_2.write(mapname=\"elevation_2\", overwrite=True)\n\n\ngs.list_grouped(type=\"raster\", pattern=\"elev*\")\n\nLet’s now explore how to convert text outputs into pandas data frames. We will get elevation univariate statistics for each land use class and parse the output into a pandas data frame.\n\nimport pandas as pd\nfrom io import StringIO\n\n\nstats = gs.read_command(\"r.univar\", \n                        flags=\"t\", \n                        map=\"elevation\", \n                        zones=\"landuse\", \n                        separator=\"pipe\").strip()\ndf = pd.read_csv(StringIO(stats), sep=\"|\")\n\ndf\n\nNext, we plot the mean elevation per class as follows:\n\nplt.figure(figsize=(10, 5))\nplt.bar(df['label'], df['mean'])\nplt.ylabel('Elevation')\nplt.title('Mean elevation by Land Cover Type')\nplt.xticks(rotation=90) \nplt.show()\n\nSimilarly, if we need to do analysis with the attributes of GRASS vector maps, it is also possible to read the attribute table as a pandas data frame. Let’s see an example with the census vector map:\n\ncensus = gs.read_command(\"v.db.select\", map=\"census\").strip()\ndf = pd.read_csv(StringIO(census), sep=\"|\")\n\ndf\n\nOnce the attribute table is a data frame, we can, e.g., filter data by a condition and plot the results.\n\nfam_size_3 = df[df[\"FAM_SIZE\"] &gt; 3.0]\n\n\nfam_size_3.plot.scatter(x=\"FAM_SIZE\", y=\"OWNER_U\")"
  },
  {
    "objectID": "fast_track_grass_and_python.html#final-remarks",
    "href": "fast_track_grass_and_python.html#final-remarks",
    "title": "Fast track to GRASS & Python in Jupyter Notebooks",
    "section": "Final remarks",
    "text": "Final remarks\nIn this tutorial, we have demonstrated, with very simple examples, how to use GRASS GIS tools together with Python, putting a special focus on data import and export as well as format conversions. Expert GRASS or Python users can then implement their workflows combining tools accordingly.\nEnjoy! \n\n\nThe development of this tutorial was funded by the US National Science Foundation (NSF), award 2303651."
  },
  {
    "objectID": "grass_gis_in_google_colab.html",
    "href": "grass_gis_in_google_colab.html",
    "title": "GRASS GIS in Google Colab",
    "section": "",
    "text": "What is Colab?\nPerhaps you have heard of Google Colaboratory or simply Colab. This is a hosted Jupyter Notebook service that requires no setup or configuration to use and provides free access to computing resources, including GPUs and TPUs. Colab is especially well suited to machine learning, data science, and education. Furthermore, it allows easy sharing of workflows which facilitates reproducibility.\nColab notebooks allow you to combine executable code and rich text in a single document, along with images, HTML, LaTeX and more. When you create your own Colab notebooks, they are stored in your Google Drive account. You can easily share your Colab notebooks with co-workers or friends, allowing them to comment on your notebooks or even edit them.\n\n\n\n\n\n\nNote\n\n\n\nSee Colab’s FAQ for more details: https://research.google.com/colaboratory/faq.html and follow the Google Colab blog in Medium at https://medium.com/google-colab.\n\n\n\n\nWhy GRASS GIS in Colab?\nSince Colab offers Jupyter notebooks in a Linux environment it is really easy to install or even compile GRASS GIS there. Also, because of the integration with Google Drive, it is a great resource to run our workflows in the cloud and export the results or keep our GRASS projects and code there. This clearly facilitates teaching workshops or courses since attendants do not need to install or download anything on their own machines.\nThere are a couple of things to consider when working with GRASS GIS within Colab though. Users will need to install GRASS GIS every time they start a new working session or notebook. Furthermore, whatever files users download within Colab will last only during the current session. If the runtime gets disconnected because of inactivity, downloaded data and outputs created within Colab, will be lost too. If users instead, mount their own Google drive, download data and create their GRASS projects there, those will be preserved even if the runtime is disconnected or the session closed.\n\n\nInstall GRASS GIS in Colab\nLet’s first print system description to know where are we:\n\n!lsb_release -a\n\nAt the time of writing this tutorial, Colab has Linux Ubuntu 22.04.3 LTS. So we add the ppa:ubuntugis repository, update and install GRASS GIS. It might take a couple of minutes according to the resources available.\n\n!add-apt-repository -y ppa:ubuntugis/ubuntugis-unstable\n!apt update\n!apt-get install -y grass-core grass-dev\nprint(\"INSTALLATION COMPLETE\")\n\nCheck that GRASS GIS is installed by asking which version is there.\n\n!grass --config version\n\n\n\nSet our working directory and download sample data\nBy default we’ll have access to the /root folder within Colab, and any data we download will be placed there. We can change that of course, it is just a Linux file system. In any case, we should bare in mind that whatever data we download within Colab, will disappear if the runtime gets disconected because of inactivity or once we close the Colab session.\nLet’s get the North Carolina sample dataset into Colab to exemplify a data download workflow. We define our folders first:\n\nimport os\n\nhomedir = os.path.expanduser('~')\ngrassdata = os.path.join(homedir, \"grassdata\")\nproject = \"nc_spm_08_grass7\"\nmapset = \"PERMANENT\"\n\nthen download the North Carolina dataset into our homedir.\n\n!wget -c https://grass.osgeo.org/sampledata/north_carolina/nc_spm_08_grass7.zip -O $homedir/nc.zip\n\nWe unzip the downloaded file within the grassdata folder in /root\n\n!unzip -o -q -d $grassdata $homedir/nc.zip\n\nand finally check it is indeed there:\n\n# List files within grassdata\nos.listdir(grassdata)\n\n\n\nStart GRASS in Colab\nWe have GRASS GIS installed and a sample project to play around. Let’s add the GRASS python packages to PATH to be able to import the grass.script and grass.jupyter libraries.\n\n# Import standard Python packages we need\nimport sys\nimport subprocess\n\n# Ask GRASS GIS where its Python packages are to be able to run it from the notebook\nsys.path.append(\n    subprocess.check_output([\"grass\", \"--config\", \"python_path\"], text=True).strip()\n)\n\n\n# Import the GRASS GIS packages\nimport grass.script as gs\nimport grass.jupyter as gj\n\nNow we are ready to start GRASS GIS within the North Carolina project.\n\nsession = gj.init(grassdata, project, mapset)\n\nLet’s show the current GRASS GIS settings and check if the session actually works:\n\ngs.gisenv()\n\nJust as an example, we will list the raster maps and display one of them using the InteractiveMap class.\n\ngs.list_grouped(type=\"raster\")\n\n\nm = gj.InteractiveMap(width = 500, tiles=\"OpenStreetMap\")\nm.add_raster(\"landclass96\")\nm.add_layer_control(position = \"bottomright\")\nm.show()\n\n\n\nConect Colab with Google Drive\nIf we do not want to loose our GRASS projects when closing the Colab notebook, we can connect Colab with our Google Drive and upload, download or create our projects there. To be able to do any of that, we need to mount our drive first (i.e., similar to what we do with external drives). We first import the drive library.\n\nfrom google.colab import drive \n\nThen, we define the mounting point. Running the cell below triggers a dialog to grant Colab access to our drive. It is possible to change accounts, too. Once that is complete, we will have access to everything we have in our GDrive folders and we can browse the content either with commands or from the left panel in the Colab notebook.\n\ndrive.mount(\"/content/drive\")\n\nWe can also mount our drive directly from the Colab interface as shown below:\n\nOnce the GDrive is mounted, we can either create a new project and start GRASS GIS there as shown above or start GRASS within an existing GRASS project in GDrive. Importantly, we can then process and analyse our data and close the session afterwards that our data will remain in GDrive for the next time.\n\n\nCreate a new GRASS project in Google Drive\nTo create a new project we can use the create_project function from the grass.script library as shown in the GRASS and Python tutorial. Let’s, for example, create a project with the EPSG code option:\n\ngs.create_project(\"/content/drive/MyDrive/grassdata/latlong_wgs84\", epsg=\"4326\")\n\n\n\nStart GRASS GIS in an existing project\nEither if you just created the project and want to start GRASS GIS there or if you already have your GRASS projects in GDrive, you just need to start GRASS wherever the project is, as shown above, given that GRASS GIS has been installed in the Colab session and libraries imported.\nCool, ah?! Enjoy! \n\n\nThe development of this tutorial was funded by the US National Science Foundation (NSF), award 2303651."
  },
  {
    "objectID": "JupyterOnWindows_OSGeo4W_Tutorial.html",
    "href": "JupyterOnWindows_OSGeo4W_Tutorial.html",
    "title": "Running GRASS in Jupyter Notebooks in Windows with OSGeo4W",
    "section": "",
    "text": "The development of the Python package grass.jupyter, has streamlined the use of GRASS GIS is Jupyter notebooks. In this tutorial we will demonstrate the recommended way of running GRASS GIS in Jupyter Notebooks for Windows users."
  },
  {
    "objectID": "JupyterOnWindows_OSGeo4W_Tutorial.html#set-up",
    "href": "JupyterOnWindows_OSGeo4W_Tutorial.html#set-up",
    "title": "Running GRASS in Jupyter Notebooks in Windows with OSGeo4W",
    "section": "Set Up",
    "text": "Set Up\nOn Windows, we’ll use the OSGeo4W package manager to setup and update GRASS GIS, Jupyterlab and other dependencies. Follow the directions below to setup Jupyter and GRASS in Windows.\n\n1. Download the OSGeo4W Network Installer\nDownload the OSGeo4W network install from here. Open it and select “Advanced Install”.\n\n\n2. Install GRASS GIS, Jupyterlab and grass.jupyter dependencies\nFollow the prompts until you get to the “Select Packages” window (the defaults are fine for most situations). Use the Search bar to find and select the following packages for install (switching from “Skip” to the version number):\n\ngrass\npython3-jupyterlab\npython3-ipywidgets\n\n\n\n3. Go make a cup of tea\nIt may take a minute to install… Click “Finish” and exit when it finishes.\n\n\n4. Open the OSGeo4W Shell and install folium\nLaunch the OSGeo4W Shell and install folium with:\npip install folium\n\n\n5. Launch Jupyter Lab\nWe’re ready to launch jupyterlab now:\njupyter lab\nThis should launch Jupyter lab in your default web browser. Use the left side panel to navigate to the notebook you wish to run and you’re ready to go!\n\n\n6. Launching Jupyter Lab in the Future\nTo launch Jupyter Lab in the future:\n\nOpen the OSGeo4W Shell\nLaunch jupyter lab with jupyter lab"
  },
  {
    "objectID": "JupyterOnWindows_OSGeo4W_Tutorial.html#start-grass-within-jupyter",
    "href": "JupyterOnWindows_OSGeo4W_Tutorial.html#start-grass-within-jupyter",
    "title": "Running GRASS in Jupyter Notebooks in Windows with OSGeo4W",
    "section": "Start GRASS within Jupyter",
    "text": "Start GRASS within Jupyter\nNow, we’re ready to code! Let’s import the GRASS GIS Python packages and launch GRASS GIS. If you want to run this tutorial, please download and unzip the North Carolina sample dataset.\n\n# Import standard python packages\nimport sys\nimport subprocess\n\n# Ask GRASS GIS where its Python packages are and add them to the path\ngrass_call = \"grass83\"\nsys.path.append(\n    subprocess.check_output([grass_call, \"--config\", \"python_path\"], text=True, shell=True).strip()\n)\n\n# Import the GRASS GIS python packages we need\nimport grass.script as gs\nimport grass.jupyter as gj\n\n# Launch a GRASS GIS session.\ngj.init(\"path/to/nc_spm_08_grass/user1\");"
  },
  {
    "objectID": "JupyterOnWindows_OSGeo4W_Tutorial.html#using-grass",
    "href": "JupyterOnWindows_OSGeo4W_Tutorial.html#using-grass",
    "title": "Running GRASS in Jupyter Notebooks in Windows with OSGeo4W",
    "section": "Using GRASS",
    "text": "Using GRASS\nNow that we have GRASS GIS running in our notebook, let’s try some basic commands.\nIn this section, we will set the color table to the elevation raster map from the GRASS GIS sample project we downloaded and then display it.\n\n# Set the computational region to the study area\ngs.parse_command(\"g.region\", \n                raster=\"elevation\", \n                flags='pg')\n\n# Set colors for elevation raster\ngs.run_command(\"r.colors\", \n              map=\"elevation\", \n              color=\"elevation\")\n\n\n# Create Map instance\nimg = gj.Map()\n# Add a raster\nimg.d_rast(map=\"elevation\")\n# Add legend\nimg.d_legend(raster=\"elevation\", at=(55, 95, 80, 84), flags=\"b\")\n# Display map\nimg.show()\n\nNow, we’re up and running! Have a look at other tutorials for inspiration on the avenues you can follow with GRASS tools combined with other Python packages."
  },
  {
    "objectID": "JupyterOnWindows_OSGeo4W_Tutorial.html#troubleshooting",
    "href": "JupyterOnWindows_OSGeo4W_Tutorial.html#troubleshooting",
    "title": "Running GRASS in Jupyter Notebooks in Windows with OSGeo4W",
    "section": "Troubleshooting",
    "text": "Troubleshooting\nSomething not working? Here are some common stumbling blocks…\n\nFileNotFoundError\n\n\nFileNotFoundError: [WinError 2] The system cannot find the file specified\n\nCheck the shell parameter in the subprocess.check_output(). On Windows, this should be shell=True. On Mac and Linux operating systems, this should be shell=False.\n\nCalledProcessError\n\n\nCalledProcessError: Command '['grass83', '--config', 'python_path']' returned non-zero exit status 1.\n\nCheck which version of GRASS GIS you have installed. On Windows, the grass_call should be grass followed by the first two digits of the version you have installed (for example, GRASS GIS 8.4 would be called with grass84). On Mac and Linux, it should be just grass.\n\nErrors from gj.init()\n\nThis command takes several different configurations of the GRASS GIS project and mapset location on your system. All the following are examples that work:\ngj.init(\"path/to/grassdata\", \"project_name\", \"mapset_name\")\ngj.init(\"path/to/project_name/mapset_name\")\ngj.init(\"../project_name/mapset_name\")\nAlso pay attention to the slash direction. Windows uses \\ in it’s file paths but the \\ character in strings is also for escaping characters (for example, putting \\n in a string will print a new line). Therefore, you’ll need to either switch to forward slashes (/) or put double back-slashes (\\\\)."
  },
  {
    "objectID": "time_series/time_series_gap_filling.html",
    "href": "time_series/time_series_gap_filling.html",
    "title": "Time series gap filling",
    "section": "",
    "text": "In this fifth part of the time series tutorials, we will go through an important topic when working with optic remote sensing derived data or products: gaps and gap filling. There are several other methods to perform missing data imputation. Here, we’ll only demonstrate the usage of GRASS GIS tools that allow us to perform gap filling in time, also called temporal interpolation. Specifically, we’ll show how to reconstruct missing data using:\nThere are different types of gaps that we might want/need to fill when working with time series data: - full maps missing, e.g. a daily time series where some days are missing because product tiles missing from the archive, or when we want to interpolate from weekly to daily data - series is complete but (some) maps have missing data because of clouds, snow, product quality flags applied, etc."
  },
  {
    "objectID": "time_series/time_series_gap_filling.html#full-maps-missing",
    "href": "time_series/time_series_gap_filling.html#full-maps-missing",
    "title": "Time series gap filling",
    "section": "Full maps missing",
    "text": "Full maps missing\nFor the case of full maps missing, GRASS GIS offers simple linear interpolation in time through the t.rast.gapfill tool. Let’s see an example: we will first aggregate our daily LST time series with a monthly granularity, then make a copy of it using t.copy, unregister a couple of maps here and there with t.unregister, apply a temporal linear interpolation with t.rast.gapfill and compare the results.\n\n# Aggregate daily time series into monthly\ngs.run_command(\"t.rast.aggregate\",\n               input=\"lst_daily\",\n               output=\"lst_monthly\", \n               basename=\"lst_monthly\",\n               method=\"average\",\n               granularity=\"1 months\",\n               suffix=\"gran\")\n\n\n# Create a copy\ngs.run_command(\"t.copy\",\n               input=\"lst_monthly\",\n               output=\"lst_monthly_copy\")\n\n# Unregister maps from lst_monthly_copy\n# Note that we remove 1, 2 and 3 consecutive maps in different periods of the year\nto_unregister=[lst_monthly_2014_03,lst_monthly_2014_10,lst_monthly_2014_11,lst_monthly_2015_06,lst_monthly_2015_07,lst_monthly_2015_08]\n\ngs.run_command(\"t.unregister\",\n               input=\"lst_monthly_copy\",\n               maps=to_unregister)\n\n# Check gaps\ngs.read_command(\"t.rast.list\",\n                input=\"lst_monthly_copy\", \n                method=\"deltagaps\")\n\n\n# Fill gaps\ngs.run_command(\"t.rast.gapfill\",\n               input=\"lst_monthly_copy\",\n               basename=\"gaps\")\n\n# Check gaps again and compare values with lst_monthly\ngs.run_command(\"t.rast.list\",\n               input=\"lst_monthly_copy\",\n               columns=\"name,start_time,min,max\",\n               where=\"start_time &lt; '2016-01-01'\")\ngs.run_command(\"t.rast.list\",\n               input=\"lst_monthly\",\n               columns=\"name,start_time,min,max\",\n               where=\"start_time &lt; '2016-01-01'\")\n\n\n# Plot the two time series for the city of Trento\n!g.gui.tplot strds=lst_monthly,lst_monthly_copy \\\n  coordinates=4410837.455830389,2559852.473498233 \\\n  title=\"Trento daily LST\" xlabel=\"Time\" ylabel=\"LST (C)\" \\\n  size=800,500 output=trento_gapfilled.png\n\n\n\n\nLinear interpolation of LST time series\n\n\n\n\n\n\n\n\nNote\n\n\n\nt.unregister allows us to remove maps from the temporal database or from a STRDS without actually removing them from the mapset, i.e., we only remove their timestamp and hence their record in the STRDS object."
  },
  {
    "objectID": "time_series/time_series_gap_filling.html#maps-with-holes",
    "href": "time_series/time_series_gap_filling.html#maps-with-holes",
    "title": "Time series gap filling",
    "section": "Maps with holes",
    "text": "Maps with holes\nFor the case when maps have no data areas (i.e. holes or gaps) because of cloud or cloud shadow masking, or as a result of QA flags application, two GRASS tools can be used, namely r.hants or r.series.lwr. When to use one or the other will mostly depend on the variable that the time series represent (i.e., temperature, NDVI, chlorophyll, etc.) and its granularity (i.e., hourly, daily, weekly, monthly, etc.).\n\nSimulating the holes\nTo demonstrate the use of r.hants and r.series.lwr with our LST time series, we will simulate the occurrence of clouds by randomly masking different provinces in our study area. This will be a very simplified case only for demonstration purposes. A proper example of how to mask clouds and apply quality assessment flags will be developed in a different series of tutorials.\nWe clip the provinces vector map with the computational region in order to get the list of polygons’ ids or cat values, that we’ll use as “clouds”.\n\n# Clip Italy provinces to the comp region\ngs.run_command(\"v.clip\",\n               input=\"italy_borders_2\",\n               output=\"italy_borders_2_clip\",\n               flags=\"r\")\n\n# Get unique categories \ncats = gs.parse_command(\"v.category\",\n                        input=\"italy_borders_2_clip\", \n                        option=\"print\")\n                        \ncats = list(cats.keys())\n\nThen we list the maps over which we will create the gaps.\n\n# Get list of monthly maps\nmaps = gs.parse_command(\"t.rast.list\",\n                         input=\"lst_monthly\",\n                         columns=\"name\",\n                         method=\"comma\",\n                         flags=\"u\")\n\nmaps = list(maps.keys())\n\nFinally, we actually use 4 random polygons to create holes in each map of the monthly LST time series. Basically, for each map of the series, we apply an inverse mask of 4 random polygons, we overwrite the maps to actually get the holes (i.e., MASK is otherwise virtual), and we remove the mask.\n\nimport random\nn=4\n\nfor i in range(len(maps)):\n    gs.run_command(\"r.mask\", \n                   vector=\"italy_borders_2_clip\", \n                   cats=random.sample(cats,n), \n                   flags=\"i\")\n    gs.mapcalc(exp=f\"{maps[i]} = {maps[i]}\", \n               overwrite=True)\n    gs.run_command(\"r.mask\", \n                   flags=\"r\")\n\nLet’s check the holes we created\n\ngaps = gj.Map(height = 500)\ngaps.d_rast(map=\"lst_monthly_2017_01\")\ngaps.show()\n\n\n\nFilling the holes\n\nHarmonic analysis of time series\nr.hants performs a Harmonic ANalysis of Time Series (HANTS) analysis in order to estimate missing values and identify outliers. This algorithm considers only the most significant frequencies expected to be present in the time profiles (e.g. determined from a preceding Fast Fourier Transform analysis), and applies a least squares curve fitting procedure based on harmonic components (sines and cosines).\nThe option nf, number of frequencies, should be carefully chosen. As a rule of thumb, the nf should be at least the estimated periodicity plus 3, e.g. for NDVI with an annual cycle (one peak per year), the number of frequencies should be at least 4 when analyzing one year. The number of frequencies should not be too large, either. Otherwise, outliers can no longer be identified because of overfitting. Moreover, the number of frequencies should be smaller than n input maps / 2 if missing values should be reconstructed.\n\n# Install extension\ngs.run_command(\"g.extension\",\n               extension=\"r.hants\")\n\n\n# Basic usage of r.hants\ngs.run_command(\"r.hants\",\n               input=maps,\n               nf=4,\n               base_period=12)\n\n\nOther r.hants options and flags that can be used to adjust the fit can be found at the tool manual page: https://grass.osgeo.org/grass-stable/manuals/addons/r.hants.html and also within the original publication.\n\n\n# List filled maps\nhants_maps = gs.list_grouped(type=\"raster\", \n                             pattern=\"*hants\")[\"italy_LST_daily\"]\n\n\n# Ccreate new time series \ngs.run_command(\"t.create\",\n               output=\"lst_monthly_hants\",\n               type=\"strds\",\n               temporaltype=\"absolute\",\n               title=\"Gap-filled monthly LST\",\n               description=\"HANTS gap-filled monthly LST - North Italy, 2014-2018\")\n\n\n# register maps\ngs.run_command(\"t.register\",\n               flags=\"i\",\n               input=\"lst_monthly_hants\",\n               type=\"raster\",\n               maps=hants_maps,\n               start=\"2014-01-01\",\n               increment=\"1 months\")\n\n\n# Print time series info\nprint(gs.read_command(\"t.info\", \n                      input=\"lst_monthly_hants\"))\n\nLet’s see a plot.\n\n!g.gui.tplot strds=lst_monthly_hants,lst_monthly \\\n  coordinates=4410837.455830389,2559852.473498233 \\\n  title=\"Trento reconstructed LST\" xlabel=\"Time\" ylabel=\"LST (C)\" \\\n  size=800,500 output=trento_hants.png\n\n\n\n\nHANTS interpolation of LST time series\n\n\nSomething important to highlight is that r.hants will fit a single model to the whole input time series. For multiple years, that might not be the best option because there won’t be any variation. So, for the case of multiple years, it is recommended to do multiple runs and then temporally patch the results.\n\n\n\n\n\n\nNote\n\n\n\nr.hants will reconstruct all cells within the input maps, whether they have gaps or not. If we want to keep the original values, we could patch the original series with the reconstructed result. That could be done as follows:\n\n# Patching\nfor i,j in zip(maps,hants_maps):\n    print(i, j)\n    out=f\"{j}_patch\"\n    gs.run_command(\"r.patch\",\n                   input=[i, j],\n                   output=out)\n\n\n\n\n\nLocal weighted regression\nr.series.lwr performs a local weighted regression (LWR) in time in order to estimate missing values and identify outliers. For each observation in the time series, the neighbor values in time are used to estimate a polynomial function that best fits the observations. The values are weighted according to their distance in time to the current observation. Values that are farther away get lower weights. The difference among the weight functions lies in how strongly the current observation is emphasized with respect to its temporal neighbors.\nThe option order determines the order of the polynomial function used to fit the observations. An order of 0 is a weighted average, an order of 1 is a linear regression. Recommended is order=2.\nAll gaps in the time series are by default interpolated, as long as the time series contains sufficient non-NULL observations. Optionally, the maximum size of gaps to be interpolated can be set with the maxgap option.\nThe module uses an adaptive bandwidth to fit the polynomial and searches for: order + 1 + dod valid values around the current observation. The degree of over-determination (dod) is the user defined number of extra temporal neighbors that should be considered for the estimation of the value at each time step.\nJust for comparison purposes, we’ll use the lst_monthly time series. However, r.series.lwr is known to be more effective when there’s no such a clear cyclic pattern or in smaller granularities, like daily or weekly, when data shows more variation.\n\n# Install extension\ngs.run_command(\"g.extension\",\n               extension=\"r.series.lwr\")\n\n\n# Run r.series.lwr\ngs.run_command(\"r.series.lwr\",\n                input=maps,\n                suffix=\"_lwr\",\n                order=2,\n                weight=\"tricube\")\n\n\n\n\n\n\n\nNote\n\n\n\nOther r.series.lwr options and flags that can be used to adjust the fit can be found at the tool manual page: https://grass.osgeo.org/grass-stable/manuals/addons/r.series.lwr.html.\n\n\nLet’s create a time series and plot the results.\n\n# List filled maps\nlwr_maps = gs.list_grouped(type=\"raster\", \n                           pattern=\"*lwr\")[\"italy_LST_daily\"]\n\n\n# Ccreate new time series \ngs.run_command(\"t.create\",\n               output=\"lst_monthly_lwr\",\n               type=\"strds\",\n               temporaltype=\"absolute\",\n               title=\"Gap-filled monthly LST\",\n               description=\"LWR gap-filled monthly LST - North Italy, 2014-2018\")\n\n\n# register maps\ngs.run_command(\"t.register\",\n               flags=\"i\",\n               input=\"lst_monthly_lwr\",\n               type=\"raster\",\n               maps=lwr_maps,\n               start=\"2014-01-01\",\n               increment=\"1 months\")\n\n\n# Print time series info\nprint(gs.read_command(\"t.info\", \n                      input=\"lst_monthly_hants\"))\n\n\n!g.gui.tplot strds=lst_monthly_lwr,lst_monthly \\\n  coordinates=4410837.455830389,2559852.473498233 \\\n  title=\"Trento reconstructed LST\" xlabel=\"Time\" ylabel=\"LST (C)\" \\\n  size=800,500 output=trento_lwr.png\n\n\n\n\nLWR interpolation of LST time series\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that there’s an overshoot towards negative values because of missing data in the first date. Extrapolation can be avoided by using the i flag for interpolation only.\n\n\n\n\n\nComparison of r.hants and r.series.lwr results\nThere are not so significant differences among the results of these two reconstructing methods, probably because it is a smoothed time series. But have a look at a comparison of applying HANTS and LWR to a Chlorophyll-a time series with 8-day granularity:\n \nMore details can be found in the Filling and Reconstructing time series of the temporal data processing wiki page."
  },
  {
    "objectID": "time_series/time_series_gap_filling.html#references",
    "href": "time_series/time_series_gap_filling.html#references",
    "title": "Time series gap filling",
    "section": "References",
    "text": "References\n\nRoerink, G., Menenti, M., Verhoef, W. 2000. Reconstructing cloudfree NDVI composites using Fourier analysis of time series. International Journal of Remote Sensing, 21 (9), 1911-1917. DOI.\nGebbert, S., Pebesma, E. 2014. TGRASS: A temporal GIS for field based environmental modeling. Environmental Modelling & Software 53, 1-12. DOI.\nGebbert, S., Pebesma, E. 2017. The GRASS GIS temporal framework. International Journal of Geographical Information Science 31, 1273-1292. DOI.\nTemporal data processing wiki page.\n\n\n\nThe development of this tutorial was funded by the US National Science Foundation (NSF), award 2303651."
  },
  {
    "objectID": "time_series/time_series_algebra.html",
    "href": "time_series/time_series_algebra.html",
    "title": "Time series algebra",
    "section": "",
    "text": "In this third part of the time series tutorials, we will go through different temporal algebra examples. There are five modules within the temporal framework that allow us to perform temporal map algebra on different types of data: t.rast.mapcalc, t.rast.algebra, t.rast3d.mapcalc, t.rast3d.algebra, and t.vect.algebra. We will focus on the raster oriented tools in this tutorial."
  },
  {
    "objectID": "time_series/time_series_algebra.html#t.rast.mapcalc-vs-t.rast.algebra",
    "href": "time_series/time_series_algebra.html#t.rast.mapcalc-vs-t.rast.algebra",
    "title": "Time series algebra",
    "section": "t.rast.mapcalc vs t.rast.algebra",
    "text": "t.rast.mapcalc vs t.rast.algebra\nBoth tools allow us to perform spatio-temporal operations on temporally sampled maps of raster time series (STRDS). Also, both tools support spatial and temporal functions. Spatial operators and functions are those used in r.mapcalc. Temporal internal variables supported for both relative and absolute time include: td() (time delta), start_time() and end_time(). There are also several useful internal temporal variables supported especially for absolute time, e.g.: start_doy(), start_year(), start_month() and so on.\nBoth t.rast.mapcalc and t.rast.algebra support temporal operations. However, only t.rast.algebra is effectively temporally aware; t.rast.mapcalc is mostly a wrapper around r.mapcalc. Indeed, t.rast.algebra is able to perform a wide range of temporal operations based on the temporal topology of maps within STRDS. Supported operators, relations and functions in t.rast.algebra include:\n\nTemporal operators: union (u), intersection (i), left reference (l), etc.\nTemporal relations: equals, during, contains, starts, etc.\nTemporal selection: : and !:.\nTemporal functions: td(), start_time(), start_doy(), #, tmap(), map(), t_snap(), buff_t(), t_shift(), etc.\nTemporal neighborhood modifier: [x,y,t].\nSpatial operators: +,-,*,/,%.\nSpatial functions: abs(x), float(x), int(x), log(x), round(x), isnull(x),null(), among others.\n\nThey can all be combined in nested expressions with conditions statements to create spatio-temporal operators! In general, expressions have the following structure: {\"spatial or select operator\", \"temporal relations\", \"temporal operator\"} and they can be combined with conditional statements such as: if(topologies, conditions, A, B) where A and B can be either space time datasets or expressions (e.g., A+B). Just for illustration purposes, let’s see some examples from the manual page:\n\nC = A {+,equal,l} B: C will have the same time stamps than A and will be A+B for all maps with equal time stamps among A and B, this is equivalent to C = A + B, i.e., equal is the default temporal relation for algebra operations and left reference is the default temporal operator.\nC = if(start_date(A) &lt; \"2005-01-01\", A + B): C will be A+B if the start date of A is earlier than Jan 1st, 2005 (if, then statement).\nC = if({equal}, A &gt; 100 && A &lt; 1600 {&&,equal} td(A) &gt; 30, B): C will have all cells from B with equal temporal relations to A, if the cells of A are in the range (100.0, 1600) of time intervals that have more than 30 time units. This is equivalent to C = if(A &gt; 100 && A &lt; 1600 && td(A) &gt; 30, B).\nC = A {:, during} tmap(event): C will contain all maps from A that are during the temporal extent of the single map ‘event’.\nC = A * map(constant_value): C will contain all raster maps from A multiplied by the raster map ‘constant_value’ (a map without time stamp).\nB = if(A &gt; 0.0 && A[-1] &gt; 0.0 && A[-2] &gt; 0.0, start_doy(A, 0), 0): B will have the DOY for all maps from A where conditions are met at three consecutive time intervals, otherwise put 0.\n\nLet’s see some examples using the LST daily time series from northern Italy. We start with something simple to also refresh what we learnt in the previous tutorial about aggregations.\n\nAnomalies\nTo estimate annual anomalies, we need the long term average and standard deviation of the whole series, and the annual averages. Then, we estimate the standardized anomalies as:\n\\[\nStdAnom_i = \\frac{Avg_i - Avg}{SD}\n\\]\nLet’s first obtain the average and standard deviation for the series:\n\n# Get general average and SD\nmethods=[\"average\",\"stddev\"]\n\nfor me in methods:\n    gs.run_command(\"t.rast.series\",\n                   input=\"lst_daily\",\n                   method=me,\n                   output=f\"lst_{me}\")\n\nand then the annual LST average:\n\n# Get annual averages\ngs.run_command(\"t.rast.aggregate\",\n               input=\"lst_daily\",\n               method=\"average\",\n               granularity=\"1 years\",\n               output=\"lst_annual_average\",\n               basename=\"lst_average\",\n               suffix=\"gran\",\n               nprocs=6)\n\nWe now use t.rast.algebra to estimate the anomalies.\n\n# Estimate annual anomalies\nexpression=\"lst_annual_anomaly = (lst_annual_average - map(lst_average)) / map(lst_stddev)\"\n\ngs.run_command(\"t.rast.algebra\",\n               expression=expression,\n               basename=\"lst_annual_anomaly\",\n               suffix=\"gran\",\n               nprocs=6)\n\nWe set the differences color palette for the whole time series and then create an animation.\n\n# Set difference color table\ngs.run_command(\"t.rast.colors\",\n               input=\"lst_annual_anomaly\",\n               color=\"difference\")\n\n\n# Animation of annual anomalies\nanomalies = gj.TimeSeriesMap(use_region=True)\nanomalies.add_raster_series(\"lst_annual_anomaly\", fill_gaps=False)\nanomalies.d_legend(color=\"black\", at=(10,40,2,6))\nanomalies.show()\n\n\n\nMonth with maximum LST\nWe will use t.rast.mapcalc to obtain the month when the maximum LST occurred during our study period. We already estimated the map with the maximum LST in the previous tutorial, but let’s refresh our memories:\n\ngs.run_command(\"t.rast.series\",\n               input=\"lst_daily\",\n               output=f\"lst_maximum\",\n               method=\"maximum\",\n               nprocs=4)\n\nThen, we use t.rast.mapcalc to compare all maps in lst_daily with the lst_maximum map and save the month only when there’s a match. The result will probably be a very sparse time series.\n\n# Get time series with month of maximum LST\nexpression=\"if(lst_daily == lst_maximum, start_month(), null())\"\n\ngs.run_command(\"t.rast.mapcalc\",\n               flags=\"n\", # register also null maps\n               inputs=\"lst_daily\",\n               output=\"month_max_lst\",\n               basename=\"month_max_lst\",\n               expression=expression,\n               nprocs=6)\n\n\n# Get basic info\nprint(gs.read_command(\"t.info\", \n                      input=\"month_min_lst\"))\n\nNow we can aggregate our sparse time series to obtain the earliest month in which the maximum LST occurred.\n\n# Get the earliest month in which the maximum appeared (method=minimum)\ngs.run_command(\"t.rast.series\",\n               input=\"month_max_lst\",\n               method=\"minimum\",\n               output=\"max_lst_date\")\n\nWe remove the intermediate time series as we were only interested in the resulting aggregated map. For that we use the tool t.remove that allow us to control what to remove depending on the combination of flags we use. In this case, we want to remove both the time series and maps within it, so we use d to remove thestrds, unregister maps from temporal database and delete them from mapset, and f to actually force the removal.\n\n# Remove month_max_lst strds\ngs.run_command(\"t.remove\",\n               flags=\"df\",\n               inputs=\"month_max_lst\")\n               \n# Check it's gone\nprint(gs.read_command(\"t.list\"))\n\nLet’s display the result using the Map class from grass.jupyter package:\n\nmm = gj.Map(width=450, use_region=True)\nmm.d_rast(map=\"max_lst_date\")\nmm.d_vect(map=\"italy\", type=\"boundary\", color=\"#4D4D4D\", width=2)\nmm.d_legend(raster=\"max_lst_date\", title=\"Month\", fontsize=10, at=(2,15,2,10))\nmm.d_barscale(length=50, units=\"kilometers\", segment=4, fontsize=14, at=(73,7))\nmm.d_northarrow(at=(90,15))\nmm.d_text(text=\"Month of maximum LST\", color=\"black\", font=\"sans\", size=4, bgcolor=\"white\")\nmm.show()\n\n\n\n\n\n\n\nQuestion\n\n\n\nHow could we have done the same in one single step? Hint: t.rast.algebra ... method=during.\n\n# Get time series with month of maximum LST\nexpression=\"month_max_lst = if({during}, lst_daily == tmap(lst_maximum), start_month(), null())\"\n\ngs.run_command(\"t.rast.algebra\",\n               basename=\"month_max_lst\",\n               expression=expression,\n               suffix=\"gran\",\n               nprocs=6)\n\nIs it really the same?\n\nexpression=\"result = max_lst_date - month_max_lst\"\ngs.rast_mapcalc(exp=expression)\ngs.raster_info(\"result\")\n\n\n\nWhat if we are interested in knowing the week number in which the annual maximum LST occurs each year? How would you do that? Can we also know if there’s any trend in the week number? i.e., does it tend to happen earlier or later?\n\n# Estimate annual max LST\ngs.run_command(\"t.rast.aggregate\",\n              input=\"lst_daily\",\n              output=\"lst_max_annual\",\n              basename=\"lst_max\",\n              method=\"maximum\",\n              granularity=\"1 years\",\n              suffix=gran)\n\n# Week number\nexp=\"week_lst_max_annual = if({contains}, lst_max_annual == lst_daily, start_week(lst_daily))\"\ngs.run_command(\"t.rast.algebra\",\n              expression=exp,\n              basename=\"week_lst_max_annual\",\n              suffix=\"gran\") \n\n# Is there a trend?\ngs.run_command(\"t.rast.series\",\n              input=\"week_lst_max_annual\",\n              method=\"slope\",\n              output=\"slope_week_lst_max_annual\")\n\n\n\nNumber of days with LST &gt;= 20 and &lt;= 30\nSome plague insects tend to thrive in a certain range of temperatures. Let’s assume this range is from 20 to 30 °C. Here, we’ll estimate the number of days within this range per year, and then, we’ll estimate the median along years.\n\n# Keep only pixels meeting the condition\nexpression=\"lst_higher20_lower30 = if(lst_daily &gt;= 20.0 && lst_daily &lt;= 30.0, 1, null())\"\n\ngs.run_command(\"t.rast.algebra\",\n               expression=expression, \n               basename=\"lst_higher20_lower30\",\n               suffix=\"gran\",\n               nproc=6, \n               flags=\"n\")\n\n\n# Count how many times per year the condition is met\ngs.run_command(\"t.rast.aggregate\",\n               input=\"lst_higher20_lower30\", \n               output=\"count_lst_higher20_lower30\",\n               basename=\"count_lst_higher20_lower30\",\n               suffix=\"gran\",\n               method=\"count\",\n               granularity=\"1 years\")\n\n\n# Check raster maps in the STRDS\ngs.run_command(\"t.rast.list\", \n               input=\"count_lst_higher20_lower30\", \n               columns=\"name,start_time,min,max\")\n\n\n# Median number of days with average lst &gt;= 20 and &lt;= 30\ngs.run_command(\"t.rast.series\",\n               input=\"count_tmean_higher20_lower30\",\n               output=\"median_count_tmean_higher20_lower30\",\n               method=\"median\")\n\n\n# Display raster map with interactive class\nh20_map = gj.InteractiveMap(width = 500, use_region=True)\nh20_map.add_raster(\"median_count_tmean_higher20_lower30\")\nh20_map.add_layer_control(position = \"bottomright\")\nh20_map.show()\n\n\n\n\n\n\n\nQuestion\n\n\n\nHow would you check if the median number of days with lst &gt;= 20 and &lt;= 30 is changing along the years?\n\n\n\n\nNumber of consecutive days with LST &lt;= -10.0\nLikewise, there are temperature thresholds that mark a limit to insects survival. Here, we’ll use the lower temperature threshold to survival. Most importantly, we we’ll count the number of consecutive days with temperatures below this threshold.\nHere, we’ll use again the temporal algebra and we’ll recall the concept of topology that we defined at the beginning of these tutorials. First, we need to create a STRDS of annual granularity that will contain only zeroes. This annual STRDS, that we call annual_mask, will be the base to add the value 1 each time the condition of less than -10 °C in consecutive days is met. Finally, we estimate the median number of days with LST lower than -10 °C over the 5 years.\n\n# Create annual mask\ngs.run_command(\"t.rast.aggregate\",\n               input=\"lst_daily\",\n               output=\"annual_mask\",\n               basename=\"annual_mask\",\n               suffix=\"gran\",\n               granularity=\"1 year\",\n               method=\"count\")\n\n\n# Replace values by zero\nexpression=\"if(annual_mask, 0)\"\n\ngs.run_command(\"t.rast.mapcalc\",\n               input=\"annual_mask\",\n               output=\"annual_mask_0\",\n               expression=expression,\n               basename=\"annual_mask_0\")\n\n\n# Calculate consecutive days with LST &lt;= -10.0\nexpression=\"lower_m10_consec_days = annual_mask_0 {+,contains,l} if(lst_daily &lt;= -10.0 && lst_daily[-1] &lt;= -10.0 || lst_daily[1] &lt;= -10.0 && lst_daily &lt;= -10.0, 1, 0)\"\n\ngs.run_command(\"t.rast.algebra\",\n               expression=expression,\n               basename=\"lower_m10\",\n               suffix=\"gran\",\n               nproc=7)\n\n\n# Inspect values\ngs.run_command(\"t.rast.list\",\n               input=\"lower_m10_consec_days\",\n               columns=\"name,start_time,min,max\")\n\n\n# Median number of consecutive days with LST &lt;= -10\ngs.run_command(\"t.rast.series\",\n               input=\"lower_m10_consec_days\",\n               output=\"median_lower_m10_consec_days\",\n               method=\"median\")\n\n\n# Display raster map with interactive class\nlt10_map = gj.InteractiveMap(width = 500, use_region=True)\nlt10_map.add_raster(\"median_lower_m10_consec_days\")\nlt10_map.add_layer_control(position = \"bottomright\")\nlt10_map.show()"
  },
  {
    "objectID": "time_series/time_series_algebra.html#references",
    "href": "time_series/time_series_algebra.html#references",
    "title": "Time series algebra",
    "section": "References",
    "text": "References\n\nGebbert, S., Pebesma, E. 2014. TGRASS: A temporal GIS for field based environmental modeling. Environmental Modelling & Software 53, 1-12. DOI.\nGebbert, S., Pebesma, E. 2017. The GRASS GIS temporal framework. International Journal of Geographical Information Science 31, 1273-1292. DOI.\nGebbert, S., Leppelt, T., Pebesma, E., 2019. A topology based spatio-temporal map algebra for big data analysis. Data 4, 86. DOI.\nTemporal data processing wiki page.\n\n\n\nThe development of this tutorial was funded by the US National Science Foundation (NSF), award 2303651."
  },
  {
    "objectID": "time_series/time_series_query_with_vector.html",
    "href": "time_series/time_series_query_with_vector.html",
    "title": "Time series querying",
    "section": "",
    "text": "In this sixth part of the time series tutorials, we will go through time series querying and compare and contrast the different tools available according to their inputs, outputs and other options. We will split tools into two groups according to their name to facilitate comparisons:"
  },
  {
    "objectID": "time_series/time_series_query_with_vector.html#temporal-tools",
    "href": "time_series/time_series_query_with_vector.html#temporal-tools",
    "title": "Time series querying",
    "section": "Temporal tools",
    "text": "Temporal tools\nAll the temporal tools that allow to query raster time series take either coordinates or a point vector map as inputs to sample one or various STRDS. Regarding outputs, the t.rast.* tools retrieve values to stdout, write them in plain text files or update the vector attribute table. In contrast, the t.vect.* tools output vector time series. Only two of these tools allow to do queries with temporal aggregation of the raster data either according to a fixed date or a date column in the case of t.rast.what.aggr or with temporal topology relations in the case of t.vect.what.strds.\n\nComparison of temporal tools that allow to query space time raster datasets.\n\n\nTools/options\nt.rast.what\nt.rast.what.aggr\nt.vect.observe.strds\nt.vect.what.strds\n\n\n\n\nPurpose\nSamples a STRDS at vector points and writes the output to stdout or text file with different layouts\nSamples a STRDS at vector points and returns aggregated values to stdout or in the attribute table\nSamples STRDSs at points from a vector map and outputs a STVDS\nSamples a STRDS at the spatio-temporal locations of a STVDS\n\n\ninput\nvector (points) or coordinates and strds\nvector (points) and strds\nvector (points) and strds(s)\nstvds (points) and strds\n\n\noutput\nstdout or plain text file\nvector, plain text or stdout\nstvds\nstvds\n\n\nwhere\nyes\n\nyes\nyes\n\n\nt_where\n\n\n\nyes\n\n\nspatial aggr\n\n\n\n\n\n\ntemporal aggr\n\nyes\n\nyes\n\n\nexample\nt.rast.what -n strds=A points=points output=result.txt layout=row\nt.rast.what.aggr input=points strds=A date=“2015-05-01” granularity=“2 months”\nt.vect.observe.strds input=points strds=A output=points_stvds vector_output=points_vector columns=A_values\nt.vect.what.strds input=points strds=A column=A_values method=average\n\n\n\nLet’s see some examples. We will first randomly extract the centroids of 15 Italian regions in our study area and save them as a point vector map to query the raster time series afterwards.\n\n# Create 15 random points and add attr table\ngs.run_command(\"v.random\", \n               output=\"sampling_points\",\n               npoints=15,\n               restrict=\"italy_borders_2_clip\",\n               seed=47)\ngs.run_command(\"v.db.addtable\",\n               map=\"sampling_points\",\n               columns=\"cat integer\")\n\n\n# Display polygons and points\npoints = gj.Map(height = 500)\npoints.d_vect(map=\"italy_borders_2_clip\", type=\"boundary\")\npoints.d_vect(map=\"sampling_points\", icon=\"basic/circle\", size=8)\npoints.d_barscale()\npoints.show()\n\n\n# Save map\npoints.save(\"points.png\")\n\n\n\n\nSample points\n\n\n\n# Calculate monthly LST time series\ngs.run_command(\"t.rast.aggregate\", \n               input=\"lst_daily\", \n               output=\"lst_monthly\",\n               basename=\"lst_monthly\",\n               granularity=\"1 month\",\n               suffix=\"gran\",\n               method=\"average\")\n\nLet’s start by using t.rast.what that will output the result in the standard output, i.e., the terminal, the GUI console or the Jupyter cell.\n\n# Get LST monthly values for the points\ngs.run_command(\"t.rast.what\",\n               points=\"sampling_points\",\n               strds=\"lst_monthly\",\n               layout=\"row\",\n               flags=\"n\")\n\nx|y|start|end|value\n4577892.8167900704|2607156.3643725100|2014-01-01 00:00:00|2014-02-01 00:00:00|-3.3495627520159\n4577892.8167900704|2607156.3643725100|2014-02-01 00:00:00|2014-03-01 00:00:00|-4.49710379464276\n4577892.8167900704|2607156.3643725100|2014-03-01 00:00:00|2014-04-01 00:00:00|2.75497920866939\n4577892.8167900704|2607156.3643725100|2014-04-01 00:00:00|2014-05-01 00:00:00|5.8034850260417\n4577892.8167900704|2607156.3643725100|2014-05-01 00:00:00|2014-06-01 00:00:00|9.28137663810487\n4577892.8167900704|2607156.3643725100|2014-06-01 00:00:00|2014-07-01 00:00:00|13.8477356770834\n4577892.8167900704|2607156.3643725100|2014-07-01 00:00:00|2014-08-01 00:00:00|15.1575793850807\n4577892.8167900704|2607156.3643725100|2014-08-01 00:00:00|2014-09-01 00:00:00|13.6287058971774\n4577892.8167900704|2607156.3643725100|2014-09-01 00:00:00|2014-10-01 00:00:00|11.6199055989584\n4577892.8167900704|2607156.3643725100|2014-10-01 00:00:00|2014-11-01 00:00:00|8.36024697580648\n4577892.8167900704|2607156.3643725100|2014-11-01 00:00:00|2014-12-01 00:00:00|2.6866315104167\n4577892.8167900704|2607156.3643725100|2014-12-01 00:00:00|2015-01-01 00:00:00|-1.45273122479836\n4577892.8167900704|2607156.3643725100|2015-01-01 00:00:00|2015-02-01 00:00:00|-3.12071761592739\n\n\n\n\n\n\nLayouts\n\n\n\nUsers can then play around with the different output layouts, i.e., row, column, timerow, to find the one that better suits their data pipelines.\n\n\nNow, to exemplify the use of t.rast.what.aggr imagine we did some mosquito trappings in two different dates and we need to know which was the average LST the two months before the trappings. Since the dates are different, we actually need to aggregate different days. This is done on the fly (i.e., without the need to aggregate the whole raster time series) by the extension t.rast.what.aggr. Let’s install it and add dates to our point vector map.\n\n# Install t.rast.what.aggr extension\ngs.run_command(\"g.extension\", extension=\"t.rast.what.aggr\")\n\n\n# Add a new date type column\ngs.run_command(\"v.db.addcolumn\", \n               map=\"sampling_points\",\n               column=\"sampling_date date\")\n               \n# Add values to the date column\ngs.run_command(\"v.db.update\", \n               map=\"sampling_points\", \n               column=\"sampling_date\",\n               value=\"2018-07-01\")\ngs.run_command(\"v.db.update\",\n               map=\"sampling_points\",\n               column=\"sampling_date\",\n               value=\"2018-08-10\",\n               where=\"cat &gt;= '9'\")\n\n\n# Inspect dates\ngs.vector_db_select(\"sampling_points\")\n\nWe will use the daily time series in this case to get the aggregation period right.\n\n# Get aggregated LST values\ngs.run_command(\"t.rast.what.aggr\", \n               input=\"sampling_points\", \n               strds=\"lst_daily\", \n               date_column=\"sampling_date\",\n               granularity=\"2 months\",\n               method=\"average\",\n               flags=\"c\")\n\nLet’s display the result by converting the attribute table into a Pandas DataFrame.\n\nimport pandas as pd\n\ndata = gs.parse_command(\"v.db.select\", \n                        map=\"sampling_points\", \n                        format=\"json\")\n                        \npd.DataFrame(data['records'])\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat would be the result if we use the monthly time series?\n\n\nLet’s demonstrate now the use of t.vect.observe.strds and t.vect.what.strds. These tools, as mentioned above, output a vector time series or stvds. Vector time series in GRASS GIS can be created either from a series of vector maps (especially if features/geometries vary in time) or from layers added to a single vector map (i.e., features are always the same, as in the case of meteorological stations).\nWe start with t.vect.observe.strds. It will create a new vector map with as many layers as raster maps there are in the strds we are querying and it will register these in a stvds.\n\ngs.run_command(\"t.vect.observe.strds\",\n               input=\"sampling_points\",\n               strds=\"lst_monthly\",\n               output=\"sp_lst_monthly\",\n               vector_output=\"sp_lst_monthly\",\n               columns=\"lst\")\n\n\n# Check the stvds is created\ngs.run_command(\"t.info\",\n               input=\"sp_lst_monthly\",\n               type=\"stvds\")\n\n\n# Check number of layers in the vector map\ngs.vector_info(\"sp_lst_monthly\")[\"num_dblinks\"]\n\n\n# Check one layer\ngs.vector_db_select(\"sp_lst_monthly\", layer=7)[\"values\"]\n\n\n# Check all layers\ngs.run_command(\"t.vect.db.select\",\n               input=\"sp_lst_monthly\")\n\nLet’s now compare the values obtained by querying the monthly LST time series with those resulting from aggregating the daily LST time series. They should be the same. For that we need to specify the sampling relation. The temporal tool that allows to specify sampling relations and do temporal aggregation is t.vect.what.strds. It requires a stvds as input, so we’ll use the one we just obtained above. We also specify the start relation, so all maps in the strds which start time matches the stvds will be aggregated. Let’s see this graphically before running the tool.\n\n\ngs.run_command(\"t.vect.what.strds\", \n               input=\"sp_lst_monthly\", \n               strds=\"lst_daily\", \n               column=\"lst_new\", \n               method=\"average\", \n               sampling=\"start\")\n\n\ngs.run_command(\"t.vect.db.select\",\n               input=\"sp_lst_monthly\")\n\nAs expected, results are exactly the same! So, if you are constrained by disk space for example, you don’t need to aggregate your entire strds if you only need aggregated values for a set of points.\n\n\n\n\n\n\nNote\n\n\n\nWe could have also used t.sample to check which maps from lst_daily would be aggregated in the new column lst_new above.\nSee for yourself and try with different sampling methods:\n\ngs.run_command(\"t.sample\", \n              input=\"lst_daily\",\n              sample=\"sp_lst_monthly\",\n              intype=\"strds\",\n              samtype=\"stvds\",\n              method=\"start\")"
  },
  {
    "objectID": "time_series/time_series_query_with_vector.html#vector-tools",
    "href": "time_series/time_series_query_with_vector.html#vector-tools",
    "title": "Time series querying",
    "section": "Vector tools",
    "text": "Vector tools\nThe main difference between temporal and vector tools to query raster time series is that vector tools can update the attribute table of the input vector without creating more layers. Regarding inputs, both v.what.strds and v.what.strds.timestamp take a point vector map as input, while v.strds.stats takes a line or polygon vector map and performs spatial aggregation, i.e. zonal stats over the full or a part of the strds. The extension v.what.strds.timestamp, somehow similar to t.rast.what.aggr, offers the possibility of reading input points’ date information from a column in the attribute table and only performs the query for the dates that match. It also offers spatial interpolation of the four nearest pixels.\n\nComparison of vector tools that allow to query space time raster datasets.\n\n\nTools/options\nv.what.strds\nv.what.strds.timestamp\nv.strds.stats\n\n\n\n\nPurpose\nRetrieves raster values from STRDSs using a point vector map\nMatches points with timestamp in the attribute table with STRDSs based on point locations in space and time, and updates the input vector’s attribute table\nCalculates zonal statistics from STRDSs and uploads values to attribute columns of a new vector map\n\n\ninput\nvector (points) and strds(s)\nvector (points) and strds(s)\nvector (lines or polygons) and strds(s)\n\n\noutput\nvector\nvector\nvector\n\n\nwhere\nyes\nyes\nyes\n\n\nt_where\nyes\nyes\nyes\n\n\nspatial aggr\n\n\nyes\n\n\ntemporal aggr\n\n\n\n\n\nspatial interp\n\nyes\n\n\n\nexample\nv.what.strds -u input=points strds=A\nv.what.strds.timestamp input=points timestamp_column=sampling_time column=A_at_sampling_time strds=A\nv.strds.stats input=areas strds=A output=areas_new method=average\n\n\n\nLet’s go through the usage of the vector tools to query raster time series now. When we run v.what.strds to query strds we can either save the results in a new vector map or update the input vector attribute table by setting the u flag. In this case, we’ll create a new vector map and do a temporal selection.\n\n# Run v.what.strds with temporal selection\ngs.run_command(\"v.what.strds\",\n               input=\"sampling_points\",\n               strds=\"lst_monthly\",\n               output=\"sp_lst_monthly_2014\",\n               t_where=\"start_time &lt;= '2015-01-01'\")\n\nLet’s check the new vector created. It contains a new column per map in the queried strds.\n\ndata = gs.parse_command(\"v.db.select\", \n                        map=\"sp_lst_monthly_2014\", \n                        format=\"json\")\n                        \npd.DataFrame(data['records'])\n\nThe tool v.what.strds.timestamp is an extension so we need to install it first. It will by default update the input vector attribute table with a column that needs to be specified by the user. Furthermore, it offers spatial interpolation of the four nearest cells via the i flag. Let’s compare the results with and without it.\n\ngs.run_command(\"g.extension\", extension=\"v.what.strds.timestamp\")\n\n\n# with spatial interp of neighbor cells\ngs.run_command(\"v.what.strds.timestamp\",\n               input=\"sampling_points\",\n               timestamp_column=\"sampling_date\",\n               column=\"lst_sampling_date_i\",\n               strds=\"lst_daily\",\n               flags=\"i\")\n               \n# without spatial interp of neighbor cells\ngs.run_command(\"v.what.strds.timestamp\",\n               input=\"sampling_points\",\n               timestamp_column=\"sampling_date\",\n               column=\"lst_sampling_date_no_i\",\n               strds=\"lst_daily\")\n\nLet’s check the results.\n\ndata = gs.parse_command(\"v.db.select\", \n                        map=\"sampling_points\", \n                        format=\"json\")\n                        \npd.DataFrame(data['records'])\n\nFinally, we’ll extract zonal statistics of a raster time series. For this, we need either a line or polygon vector map as input. We’ll use the map of italian municipalities and demonstrate the use of spatial (where) and temporal (t_where) selection.\n\n# Install v.strds.stats extension\ngs.run_command(\"g.extension\", extension=\"v.strds.stats\")\n\n\n# Extract August average LST for Milano municipality\ngs.run_command(\"v.strds.stats\",\n               input=\"italy_borders_3\",\n               strds=\"lst_monthly\",\n               where=\"NAME_3 == 'Milano'\",\n               t_where=\"strftime('%m', start_time)='08'\",\n               output=\"milano_lst_august\",\n               method=\"average\")\n\n\ngs.vector_db_select(\"milano_lst_august\")[\"values\"]\n\nLet’s now try to find out which municipality in northern Italy had the highest August average temperature each year?\n\n# Clip municipalities to computational region\ngs.run_command(\"v.clip\", \n               input=\"italy_borders_3\", \n               output=\"italy_borders_3_clip\", \n               flags=\"r\")\n\n\n# Extract summer average LST municipalities\ngs.run_command(\"v.strds.stats\",\n               input=\"italy_borders_3_clip\",\n               strds=\"lst_monthly\",\n               t_where=\"strftime('%m', start_time)='08'\",\n               output=\"municip_lst_august\",\n               method=\"average\")\n\n\n# Check the output table\ndata = gs.parse_command(\"v.db.select\", \n                        map=\"municip_lst_august\", \n                        format=\"json\")\n                        \ntable = pd.DataFrame(data['records'])\ntable\n\n\n# List with column names\ncols = list(table.columns[-5:])\n\n# Dictionary to store results\nresults = {}\n\nfor col in cols:\n    # Find the maximum value in the column\n    max_value = table[col].max()\n    \n    # Find the index of the row with the maximum value\n    max_index = table[col].idxmax()\n    \n    # Find the corresponding value in column 'D'\n    municipality = table.loc[max_index, \"NAME_3\"]\n    \n    # Store the results\n    results[col] = {'max_value': max_value, 'municipality': municipality}\n\n# Display the results\nfor col, res in results.items():\n    print(f\"Column '{col}':\")\n    print(f\"  Maximum value: {res['max_value']}\")\n    print(f\"  Municipality name: {res['municipality']}\")\n    print()\n\nThe highest average temperature in August varied among years and municipalities, however, Campi Bisenzio in the province of Florence, had the highest value both in 2016 and 2017."
  },
  {
    "objectID": "time_series/time_series_query_with_vector.html#references",
    "href": "time_series/time_series_query_with_vector.html#references",
    "title": "Time series querying",
    "section": "References",
    "text": "References\n\nGebbert, S., Pebesma, E. 2014. TGRASS: A temporal GIS for field based environmental modeling. Environmental Modelling & Software 53, 1-12. DOI.\nGebbert, S., Pebesma, E. 2017. The GRASS GIS temporal framework. International Journal of Geographical Information Science 31, 1273-1292. DOI.\nTemporal data processing wiki page.\n\n\n\nThe development of this tutorial was funded by the US National Science Foundation (NSF), award 2303651."
  },
  {
    "objectID": "good_looking_plots_in_grass.html",
    "href": "good_looking_plots_in_grass.html",
    "title": "Making plots with GRASS GIS",
    "section": "",
    "text": "In previous tutorials we saw examples of how to convert GRASS GIS raster and vector maps into Python and R objects to perform data analysis and visualizations. There are some GRASS GIS tools, mostly based in the well known matplotlib Python library, that allow us to create plots for data visualization without the need to explicitly convert GRASS data. Here are these plotting tools for raster, vector and time series data within GRASS GIS:\nIn this tutorial, we’ll demonstrate their use with maps from the North Carolina full dataset. We’ll also use a special mapset containing MODIS LST data products to exemplify tools’ usage with time series data. While these tools can be invoked from the GUI menu or Tools tab, we will show how the GRASS commands look like so you can run them from the terminal or the Console tab of the GUI. We also show the command wrapping for Python scripts using the grass.script package. You can test them in the Python tab. The use of commands facilitates reproducibility and quick testing of small changes and tweaks."
  },
  {
    "objectID": "good_looking_plots_in_grass.html#raster-plotting-tools",
    "href": "good_looking_plots_in_grass.html#raster-plotting-tools",
    "title": "Making plots with GRASS GIS",
    "section": "Raster plotting tools",
    "text": "Raster plotting tools\n\nr.boxplot\nr.boxplot is a GRASS GIS addon that allows us to make boxplots with our GRASS raster maps. It also allows to use a zonal map like a land cover classification to draw boxplots of a certain variable per classes, i.e., land cover classes. The tool then contemplates some nice features like the possibility to plot per class boxplots of the same color that the class is assigned in the zonal map or create a point vector map with the locations of the outliers, among other tweaks. Let’s see an example using a zonal map, plotting outliers and coloring boxes with the colors of the zonal map classes:\n\nGRASSPython\n\n\n\ng.extension extension=r.boxplot\nr.boxplot -oc input=elevation zones=landclass96 output=r.boxplot.png\n\n\n\n\ngs.run_command(\"g.extension\", extension=\"r.boxplot\")\ngs.run_command(\"r.boxplot\", \n               input=\"elevation\", \n               zones=\"landclass96\", \n               raster_statistics=\"median,IQR\", \n               output=\"r.boxplot.png\",\n               flags=\"oc\")\n\n\n\n\n\n\n\nr.series.boxplot\nr.series.boxplot draws boxplots of a series of input raster maps that might represent different times, spectral bands in satellite imagery or other kind of variation. If users are interested in e.g., ploting the spectral signature of different land cover classes, they can alternatively set masks and recreate the boxplot series. Let’s see an example for developed and forested classes.\n\nGRASSPython\n\n\n\n# install the extension\ng.extension extension=r.series.boxplot\n# add landsat mapset to the list of accessible mapsets\ng.mapsets mapset=landsat operation=add\n# list of maps and labels\nbands=`g.list type=raster pattern=\"lsat7_2000*\" exclude=\"*6*,*8*\" sep=comma`\nlabels=\"band1,band2,band3,band4,band5,band7\"\n\nr.mask raster=landclass96 maskcats=1\nr.series.boxplot map=$bands bxcolor=grey text_labels=$labels output=r.series.boxplot_developed.png\n\nr.mask -r \n\nr.mask raster=landclass96 maskcats=5\nr.series.boxplot map=$bands bxcolor=grey \\\n  text_labels=$labels output=r.series.boxplot_forest.png\n\n\n\n\ngs.run_command(\"g.extension\", extension=\"r.series.boxplot\")\n\ngs.run_command(\"g.mapsets\", mapset=\"landsat\", operation=\"add\")\n\nbands = gs.list_grouped(type=\"raster\", pattern=\"lsat7_2000*\", exclude=\"*6*,*8*\")[\"landsat\"]\nlabels = [\"band1\", \"band2\", \"band3\", \"band4\", \"band5\", \"band7\"]\n\ngs.run_command(\"r.mask\", raster=\"landclass96\", maskcats=\"1\")\ngs.run_command(\"r.series.boxplot\", \n              map=bands, \n              bxcolor=\"grey\", \n              text_labels=labels, \n              output=\"r.series.boxplot_developed.png\")\n\ngs.run_command(\"r.mask\", flags=\"r\")\n\ngs.run_command(\"r.mask\", raster=\"landclass96\", maskcats=\"5\")\n\ngs.run_command(\"r.series.boxplot\", \n              map=bands, \n              bxcolor=\"grey\", \n              text_labels=labels, \n              output=\"r.series.boxplot_forested.png\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nClass developed\n\n\n\n\n\n\n\nClass forest"
  },
  {
    "objectID": "good_looking_plots_in_grass.html#vector-plotting-tools",
    "href": "good_looking_plots_in_grass.html#vector-plotting-tools",
    "title": "Making plots with GRASS GIS",
    "section": "Vector plotting tools",
    "text": "Vector plotting tools\n\nv.boxplot\nv.boxplot draws the boxplot of values in a vector map attribute column. It also provides an option to group by categories in a second attribute column.\n\nGRASSPython\n\n\n\ng.extension extension=v.histogram\n\nv.boxplot -o -r map=bridges column=WIDTH group_by=YEAR_BUILT where=\"YEAR_BUILT &lt; '1920'\" order=ascending plot_output=boxplot_bridges_width_per_year.png\n\n\n\n\ngs.run_command(\"g.extension\", extension=\"v.histogram\")\n\ngs.run_command(\"v.boxplot\",\n              map=\"bridges\", \n              column=\"WIDTH\", \n              group_by=\"YEAR_BUILT\", \n              where=\"YEAR_BUILT &lt; '1920'\", \n              order=\"ascending\", \n              plot_output=\"boxplot_bridges_width_per_year.png\", \n              flags=\"or\")\n\n\n\n\n\n\n\nv.scatterplot\nv.scatterplot creates a scatterplot with the values of two attribute columns from a vector map. It provides many arguments to control different plot features and it exposes some nice matplotlib functionality to do bining, add trend lines and confidence ellipses. While there’s r.scatterplot for raster data, it does not create a plot but a vector map. Users can, however, sample raster maps with a vector and then create scatterplots from the sampled data.\n\nGRASSPython\n\n\n\ng.extension extension=v.scatterplot\n\nv.scatterplot map=bridges x=YEAR_BUILT y=WIDTH trendline=polynomial degree=1 line_color=red type=density bins=10,10 file_name=scatterplot_bridges_width_vs_year.png\n\n\n\n\ngs.run_command(\"g.extension\", extension=\"v.scatterplot\")\n\ngs.run_command(\"v.scatterplot\", \n              map=\"bridges\", \n              x=\"YEAR_BUILT\", \n              y=\"WIDTH\", \n              trendline=\"polynomial\", \n              degree=1, \n              line_color=\"red\", \n              type=\"density\", \n              bins=\"10,10\", \n              file_name=\"scatterplot_bridges_width_vs_year.png\")\n\n\n\n\n\n\n\nv.histogram\nv.histogram draws a histogram of the values in a vector map attribute column. The tool provides basic options to select values according to a condition and set the number of bins.\n\nGRASSPython\n\n\n\ng.extension extension=v.histogram\n\nv.histogram map=bridges column=WIDTH where=\"YEAR_BUILT &lt; '1940'\" plot_output=histogram_bridges_width.png\n\n\n\n\ngs.run_command(\"g.extension\", extension=\"v.histogram\")\n\ngs.run_command(\"v.histogram\", \n              map=\"bridges\", \n              column=\"WIDTH\", \n              where=\"YEAR_BUILT &lt; '1940'\", \n              plot_output=\"histogram_bridges_width.png\")"
  },
  {
    "objectID": "good_looking_plots_in_grass.html#time-series-plotting-tools",
    "href": "good_looking_plots_in_grass.html#time-series-plotting-tools",
    "title": "Making plots with GRASS GIS",
    "section": "Time series plotting tools",
    "text": "Time series plotting tools\n\ng.gui.tplot\ng.gui.tplot is part of GRASS GIS core distribution and it allows to plot the values of raster and vector time series. Users can pass coordinate pairs for the case of raster time series and ids plus attribute column in the case of vector time series. The module also supports to display the trend line based on a linear regression and the R-squared value, visualize pop-up annotations, export the time series values to a text file, among other. Let’s see an example for the MODIS LSD DAY monthly raster time series.\n\nGRASSPython\n\n\n\ng.region -p raster=MOD11B3.A2015001.h11v05.single_LST_Day_6km\ng.gui.tplot -l strds=LST_Day_monthly coordinates=413831,196000 xlabel=\"Time\" ylabel=\"LST (K*50)\" output=LST_plot.png size=1000,800\n\n\n\n\ngs.read_command(\"g.region\", \n                raster=\"MOD11B3.A2015001.h11v05.single_LST_Day_6km\")\n                \ngs.run_command(\"g.gui.tplot\", \n              strds=\"LST_Day_monthly\", \n              coordinates=\"413831,196000\", \n              xlabel=\"Time\", \n              ylabel=\"LST (K*50)\", \n              output=\"LST_plot.png\", \n              size=\"1000,800\", \n              flags=\"l\")\n\n\n\n\n\n\n\nt.rast.boxplot\nt.rast.boxplot draws boxplots from raster maps in a space-time raster dataset, hence the x axis is determined by the STRDS temporal granularity, i.e., day, week, month, etc. Let’s see an example for plotting monthly LST within the state of North Carolina.\n\nGRASSPython\n\n\n\ng.extension extension=t.rast.boxplot\ng.region -p vector=boundary_county align=MOD11B3.A2015001.h11v05.single_LST_Day_6km\nr.mask vector=boundary_county\nt.rast.boxplot -o input=LST_Day_monthly dpi=300 rotate_labels=90 font_size=11 date_format=\"%Y-%m\" bx_width=0.7 bx_color=195:194:194:255 flier_color=77:77:77:255\n\n\n\n\ngs.run_command(\"g.extension\", extension=\"t.rast.boxplot\")\n\ngs.read_command(\"g.region\", vector=\"boundary_county\", align=\"MOD11B3.A2015001.h11v05.single_LST_Day_6km\")\n\ngs.run_command(\"r.mask\", vector=\"boundary_county\")\n\ngs.run_command(\"t.rast.boxplot\", \n              input=\"LST_Day_monthly\", \n              dpi=\"300\", \n              rotate_labels=90, \n              font_size=11, \n              date_format=\"%Y-%m\", \n              bx_width=0.7, \n              bx_color=\"195:194:194:255\", \n              flier_color=\"77:77:77:255\", \n              flags=\"o\")\n\n\n\n\n\nIf users would like to compare boxplot time series representing different areas, they could alternatively set masks for their areas of interest and then create the respective boxplot time series.\n\nGRASSPython\n\n\n\nr.mask vector=geology where=\"GEO_NAME LIKE '%Zat%'\"\nt.rast.boxplot -o input=LST_Day_monthly dpi=300 rotate_labels=90 font_size=11 date_format=\"%Y-%m\" bx_width=0.7 bx_color=195:194:194:255 flier_color=77:77:77:255\n\nr.mask -r\n\nr.mask vector=geology where=\"GEO_NAME LIKE '%Qp%'\"\nt.rast.boxplot -o input=LST_Day_monthly dpi=300 rotate_labels=90 font_size=11 date_format=\"%Y-%m\" bx_width=0.7 bx_color=195:194:194:255 flier_color=77:77:77:255\n\n\n\n\ngs.run_command(\"r.mask\", vector=\"geology\", where=\"GEO_NAME LIKE '%Zat%'\")\n\ngs.run_command(\"t.rast.boxplot\", \n              input=\"LST_Day_monthly\", \n              dpi=300, \n              rotate_labels=90, \n              font_size=11, \n              date_format=\"%Y-%m\", \n              bx_width=0.7, \n              bx_color=\"195:194:194:255\", \n              flier_color=\"77:77:77:255\", \n              flags=\"o\")\n\ngs.run_command(\"r.mask\", flags=\"r\")\n\ngs.run_command(\"r.mask\", vector=\"geology\", where=\"GEO_NAME LIKE '%Qp%'\")\n\ngs.run_command(\"t.rast.boxplot\", \n              input=\"LST_Day_monthly\", \n              dpi=300, \n              rotate_labels=90, \n              font_size=11, \n              date_format=\"%Y-%m\", \n              bx_width=0.7, \n              bx_color=\"195:194:194:255\", \n              flier_color=\"77:77:77:255\", \n              flags=\"o\")\n\n\n\n\n\n\nt.rast.line\nt.rast.line draws line plots from raster maps in a space-time raster dataset and also allows to pass a zonal map to compare average temporal changes of different areas of interest in the same plot.\n\nGRASSPython\n\n\n\ng.extension extension=t.rast.line\nt.rast.line input=LST_Day_monthly zones=boundary_county_500m y_label=\"LST (K*50)\" date_format=%Y-%m\n\n\n\n\ngs.run_command(\"g.extension\", extension=\"t.rast.line\")\n\ngs.run_command(\"t.rast.line\", \n              input=\"LST_Day_monthly\", \n              zones=\"boundary_county_500m\", \n              y_label=\"LST (K*50)\", \n              date_format=\"%Y-%m\")"
  },
  {
    "objectID": "fast_track_grass_and_R.html",
    "href": "fast_track_grass_and_R.html",
    "title": "Fast track to GRASS with R: the rgrass package",
    "section": "",
    "text": "The rgrass package allows us to interact with GRASS tools (and data) serving as an interface between GRASS GIS and R. The rgrass package is developed and maintained by Roger Bivand and can be found at: https://github.com/rsbivand/rgrass/. In this fast track tutorial, we will learn how to use GRASS GIS from R."
  },
  {
    "objectID": "fast_track_grass_and_R.html#rgrass-main-functions",
    "href": "fast_track_grass_and_R.html#rgrass-main-functions",
    "title": "Fast track to GRASS with R: the rgrass package",
    "section": "rgrass main functions",
    "text": "rgrass main functions\nThe main functions within rgrass are the following:\n\ninitGRASS(): starts a GRASS session from R.\nexecGRASS(): executes GRASS commands from R.\ngmeta(): prints GRASS session metadata like database, project, mapset, computational region settings and CRS.\nread_VECT() and read_RAST(): read vector and raster maps from a GRASS project into R.\nwrite_VECT() and write_RAST(): write vector and raster objects from R into a GRASS project.\n\n\n\n\n\n\n\nNote\n\n\n\nFor further details on rgrass functionality, usage examples and data format coercion, see: https://rsbivand.github.io/rgrass/."
  },
  {
    "objectID": "fast_track_grass_and_R.html#basic-usage-choose-your-own-adventure",
    "href": "fast_track_grass_and_R.html#basic-usage-choose-your-own-adventure",
    "title": "Fast track to GRASS with R: the rgrass package",
    "section": "Basic usage: Choose your own adventure",
    "text": "Basic usage: Choose your own adventure\nIf you are a regular R user that needs to use GRASS GIS functionality because, well, you know it rocks, rgrass has your back. For example, maybe you struggle with large raster datasets in R or you need some specific tool, like watershed delineation for a large high resolution DEM. We will show here the way to use GRASS tools within your R workflows.\nOn the other hand, if you already use GRASS as your geospatial data processing engine, you most likely have your spatial data within GRASS projects. You might need however to do some statistical analysis, some modelling and prediction or create publication ready visualizations in R. In such cases, you can start a GRASS session in your project from R or RStudio.\nLet’s see the general basic steps and then dive into the details:\n\nMake sure GRASS GIS is installed.\nOpen R (or RStudio)\nLoad rgrass library with library(rgrass)\nStart a GRASS session with initGRASS()\nUse GRASS tools through execGRASS()\nUse read_VECT(), read_RAST(), write_VECT() and write_RAST() to read data from and write data into GRASS database.\n\n\n\n\n\n\n\nNote\n\n\n\nGRASS raster and vector maps are translated into terra’s package SpatRaster and SpatVector objects, respectively. These objects can then, within R, be easily coerced to other types of spatial objects such as simple features (sf), stars, etc.\nSee terra vignettes with further explanations and examples: https://rspatial.github.io/terra/.\n\n\n\nA. Use GRASS GIS tools within your R spatial workflows\nWe start R or Rstudio and load the rgrass library. It will tell us that GRASS is not running, but we know that already… and that’s about to change in a moment.\n\nlibrary(rgrass)\n\nIn case you need to include some of the cool GRASS tools within your R workflow, the initGRASS() function allows you to create temporary GRASS projects to use GRASS tools on R objects. This is equivalent to what QGIS does when you use GRASS tools via the QGIS Processing Toolbox.\nFirst, we will use initGRASS() to create a temporary GRASS project based on the extent, resolution and CRS of a raster or vector R object, likely the one we want to process or one that has the extent of our study area. Hence, we need to pass a reference spatial grid via the SG parameter. Then, we will write our R objects into the temporary GRASS project, run the desired processes, and export the outputs back to the R environment.\nLet’s start with getting some spatial data, e.g., a raster file, into R.\n\nlibrary(terra)\nf &lt;- system.file(\"ex/elev.tif\", package=\"terra\")\nr &lt;- rast(f)\nplot(r)\n\nNow, we will start GRASS GIS in a temporary folder. By specifying SG = r, the GRASS project is internally created with raster r’s object CRS (BTW, you can check that with crs(r)), extent and resolution. These latter define the GRASS computational region that will affect all raster processing, i.e., all new raster maps generated within GRASS GIS will have the same extent and resolution of the map provided. If you wish to change the computational region later on, you can use the g.region GRASS tool with execGRASS(\"g.region --h\").\nOptionally, we can specify which GRASS binary to use with grassBin. This might be useful in case we have several GRASS versions on our system. If not provided, initGRASS() will attempt to find it in default locations depending on your operating system.\n\n# Start GRASS GIS from R\ninitGRASS(home = tempdir(),\n          SG = r, \n          override = TRUE)\n\nNow, we can write our SpatRaster into the GRASS temporary project.\n\nwrite_RAST(r, \"terra_elev\")\n\nAlternatively, we can use GRASS importing tools to import common raster and vector formats. Data will be reprojected if needed.\n\nexecGRASS(\"r.import\", input=f, output=\"test\")\n\nLet’s check both raster maps (test and terra_elev) are indeed within the project and run the GRASS tool r.slope.aspect on one of them.\n\nexecGRASS(\"g.list\", type = \"raster\")\n\n\nexecGRASS(\"r.slope.aspect\", \n          elevation = \"terra_elev\", \n          slope = \"slope\",\n          aspect = \"aspect\")\n\n\nexecGRASS(\"g.list\", type = \"raster\")\n\nLet’s get slope and aspect maps into R\n\ngrass_maps &lt;- read_RAST(c(\"aspect\", \"slope\"))\ngrass_maps\n\nNow that the output maps are back into our R environment, we can plot them, do further analysis or write them into other raster formats, in which case we use terra::writeRaster() function.\n\nplot(grass_maps)\n\n\nwriteRaster(grass_maps, \"grass_maps.tif\", overwrite=TRUE)\n\nAlternatively, we can use GRASS GIS exporting tools like r.out.gdal and v.out.ogr, to directly save our outputs into common raster or vector formats, respectively.\n\nexecGRASS(\"r.out.gdal\", input=\"slope\", output=\"slope.tif\", format=\"GTiff\", flags=\"overwrite\")\n\n\n\nB. Use R tools within GRASS GIS workflows\nLet’s see an example for the case when we do our geospatial data processing within GRASS GIS and hence have all the spatial data organized within GRASS projects but we need to run some statistical analysis, modelling, prediction or visualization in R.\n\nlibrary(rgrass)\n\nWe start GRASS GIS from within R or RStudio using the initGRASS() function. Since we want to start GRASS GIS in a specific project and mapset, we need to specify them.\n\n# Start GRASS GIS from R\ninitGRASS(gisDbase = path.expand(\"~/grassdata/\"),\n          location = \"nc_basic_spm_grass7\",\n          mapset = \"PERMANENT\",\n          override = TRUE,\n          remove_GISRC = TRUE)\n\nWe can now list and read our GRASS raster and vector maps into R and do our statistical analysis, modelling and/or visualizations using other R packages. Here, we will demonstrate the use of all the main rgrass functions mentioned above.\nLet’s then list our GRASS raster and vector maps:\n\n# List GRASS raster maps\nexecGRASS(\"g.list\", type=\"raster\")\n\n\n# List GRASS vector maps\nexecGRASS(\"g.list\", type=\"vector\")\n\nThe resulting map lists could be saved in an R object that we can subset later in case we want to import several but not all raster maps, for example. Let’s see how to do that.\n\n# Save map list in an object\nrast_list &lt;- execGRASS(\"g.list\", type=\"raster\")\n\n# Retrieve only the map list from standard output\nrast_list &lt;- attributes(rast_list)$resOut\n\n# Import elevation and landuse\nto_import &lt;- c(\"elevation\", \"landuse\") # optionally, by position: rast_list[c(3,7)]\n\nmaplist &lt;- list()\nfor (i in to_import) {\n  maplist[[i]] &lt;- read_RAST(i)\n}\n\nmaplist\n\nRemember that raster objects will always be exported from GRASS GIS following the computational region settings. So, bear that in mind when reading into R which will hold them in memory. Vectors however will be exported in their full extent.\nLet’s load the terra library to quickly display our recently imported raster maps:\n\nlibrary(terra)\nplot(maplist$elevation)\n\nOptionally, we could stack our two SpatRaster objects together and plot them together:\n\nrstack &lt;- rast(maplist)\nplot(rstack)\n\nLet’s create a boxplot of elevation per land class.\n\nboxplot(rstack$elevation, rstack$landuse, maxcell=50000)\n\nLet’s import a vector map, too, and explore its attributes.\n\ncensus &lt;- read_VECT(\"census\")\nhead(census)\n\n\nsummary(census$TOTAL_POP)\n\n\nplot(census, \"P25_TO_34\", type=\"interval\", breaks=5, plg=list(x=\"topright\"))\n\nLet’s do some interactive visualization with mapview.\n\nlibrary(mapview)\nmapview(rstack$elevation) + census\n\nWe highly recommend you to check the tmap package to make really appealing and publication ready maps.\nTo exemplify the use of write_* functions, let’s do a simple operation with the landuse raster map. We will apply a custom function that makes NULL all values less than 4.\n\nresult &lt;- app(rstack$landuse, fun=function(x){ x[x &lt; 4] &lt;- NA; return(x)} )\nplot(result)\n\nTo use this new raster in GRASS GIS, for example as an input to a GRASS tool, we need to call write_RAST function:\n\nwrite_RAST(result, \"result_from_R\", overwrite = TRUE)\n\nThe new raster is now written as a GRASS raster and can be listed:\n\nexecGRASS(\"g.list\", parameters = list(type=\"raster\", pattern=\"result*\"))\n\nFinally, there is yet another way in which you can use GRASS and R together, and it involves calling R from the GRASS terminal. In this way, rgrass will read all GRASS session environmental variables, and you won’t need to use initGRASS(). It goes more or less like this:\n\nOpen GRASS GIS\nType R or rstudio & in the GRASS terminal\nLoad rgrass library with library(rgrass)\nUse read_VECT(), read_RAST() to read data from GRASS GIS into R\nDo your analysis or plotting in R\nWrite data (back) to GRASS database with write_VECT() and write_RAST()\nQuit R quit() and get back to GRASS terminal.\n\nStarting GRASS GIS...\n\n          __________  ___   __________    _______________\n         / ____/ __ \\/   | / ___/ ___/   / ____/  _/ ___/\n        / / __/ /_/ / /| | \\__ \\\\_  \\   / / __ / / \\__ \\\n       / /_/ / _, _/ ___ |___/ /__/ /  / /_/ // / ___/ /\n       \\____/_/ |_/_/  |_/____/____/   \\____/___//____/\n\nWelcome to GRASS GIS 8.4.0\nGRASS GIS homepage:                      https://grass.osgeo.org\nThis version running through:            Bash Shell (/bin/bash)\nHelp is available with the command:      g.manual -i\nSee the licence terms with:              g.version -c\nSee citation options with:               g.version -x\nIf required, restart the GUI with:       g.gui wxpython\nWhen ready to quit enter:                exit\n\nLaunching &lt;wxpython&gt; GUI in the background, please wait...\n[Raster MASK present]\nGRASS nc_basic_spm_grass7/PERMANENT:~ &gt; R\n\nR version 4.3.1 (2023-06-16) -- \"Beagle Scouts\"\nCopyright (C) 2023 The R Foundation for Statistical Computing\nPlatform: x86_64-pc-linux-gnu (64-bit)\n\nR is free software and comes with ABSOLUTELY NO WARRANTY.\nYou are welcome to redistribute it under certain conditions.\nType 'license()' or 'licence()' for distribution details.\n\n  Natural language support but running in an English locale\n\nR is a collaborative project with many contributors.\nType 'contributors()' for more information and\n'citation()' on how to cite R or R packages in publications.\n\nType 'demo()' for some demos, 'help()' for on-line help, or\n'help.start()' for an HTML browser interface to help.\nType 'q()' to quit R.\n\n&gt; library(rgrass)\nGRASS GIS interface loaded with GRASS version: GRASS 8.4.0 (2024)\nand location: nc_basic_spm_grass7\n&gt; \nEnjoy!"
  },
  {
    "objectID": "fast_track_grass_and_R.html#references",
    "href": "fast_track_grass_and_R.html#references",
    "title": "Fast track to GRASS with R: the rgrass package",
    "section": "References",
    "text": "References\n\nBivand R (2024). rgrass: Interface Between ‘GRASS’ Geographical Information System and ‘R’. R package version 0.4-1, https://CRAN.R-project.org/package=rgrass.\n\n\n\nThe development of this tutorial was funded by the US National Science Foundation (NSF), award 2303651."
  }
]