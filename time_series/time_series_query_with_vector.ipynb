{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Time series querying\n",
    "author: Veronica Andreo\n",
    "date: today\n",
    "format:\n",
    "  html:\n",
    "    code-tools: true\n",
    "    code-copy: true\n",
    "    code-fold: false\n",
    "engine: knitr\n",
    "execute:\n",
    "  eval: false\n",
    "  keep-ipynb: true\n",
    "editor:\n",
    "  markdown:\n",
    "    wrap: 80\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this sixth part of the time series tutorials, we will go through time series\n",
    "querying and compare and contrast the different tools available according to \n",
    "their inputs, outputs and other options. \n",
    "We will split tools into two groups according to their name to facilitate \n",
    "comparisons:\n",
    "\n",
    "- temporal tools: [t.rast.what](https://grass.osgeo.org/grass-stable/manuals/t.rast.what.html), [t.rast.what.aggr](https://grass.osgeo.org/grass-stable/manuals/addons/t.rast.what.aggr.html),[t.vect.observe.strds](https://grass.osgeo.org/grass-stable/manuals/t.vect.observe.strds.html), [t.vect.what.strds](https://grass.osgeo.org/grass-stable/manuals/t.vect.what.strds.html) and, \n",
    "- vector tools: [v.what.strds](https://grass.osgeo.org/grass-stable/manuals/v.what.strds.html), [v.what.strds.timestamp](https://grass.osgeo.org/grass-stable/manuals/addons/v.what.strds.timestamp.html), [v.strds.stats](https://grass.osgeo.org/grass-stable/manuals/addons/v.strds.stats.html).\n",
    "\n",
    "::: {.callout-note title=\"Setup\"}\n",
    "This tutorial can be run locally or in Google Colab. However, make sure you\n",
    "install GRASS GIS 8.4+, download the \n",
    "[LST sample project]() \n",
    "and set up your project as explained in the \n",
    "[first part](time_series_management_and_visualization.qmd) of these time\n",
    "series tutorials.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# GRASS GIS database variables\n",
    "grassbin = \"grass-dev\"\n",
    "grassdata = os.path.join(os.path.expanduser('~'), \"grassdata\")\n",
    "project = \"eu_laea\"\n",
    "mapset = \"italy_LST_daily\"\n",
    "\n",
    "sys.path.append(\n",
    "    subprocess.check_output([grassbin, \"--config\", \"python_path\"], text=True).strip()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "\n",
    "# Import the GRASS GIS packages we need\n",
    "import grass.script as gs\n",
    "import grass.jupyter as gj\n",
    "\n",
    "# Start the GRASS GIS Session\n",
    "session = gj.init(grassdata, project, mapset);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal tools\n",
    "\n",
    "All the temporal tools that allow to query raster time series take either \n",
    "coordinates or a point vector map as inputs to sample one or various STRDS. \n",
    "Regarding outputs, the *t.rast.\\** tools retrieve values to stdout, write\n",
    "them in plain text files or update the vector attribute table. In contrast, \n",
    "the *t.vect.\\** tools output vector time series. Only two of these tools\n",
    "allow to do queries with temporal aggregation of the raster data either \n",
    "according to a fixed date or a date column in the case of\n",
    "*t.rast.what.aggr* or with temporal topology relations in the case of \n",
    "*t.vect.what.strds*.\n",
    "\n",
    "\n",
    ": Comparison of temporal tools that allow to query space time raster datasets.\n",
    "\n",
    "| Tools/<br>options | [t.rast.what](https://grass.osgeo.org/grass-stable/manuals/t.rast.what.html) | [t.rast.what.aggr](https://grass.osgeo.org/grass-stable/manuals/addons/t.rast.what.aggr.html) | [t.vect.observe.strds](https://grass.osgeo.org/grass-stable/manuals/t.vect.observe.strds.html) | [t.vect.what.strds](https://grass.osgeo.org/grass-stable/manuals/t.vect.what.strds.html) |\n",
    "|---|---|---|---|---|\n",
    "| Purpose | Samples a STRDS at vector points and writes the output to stdout or text file with different layouts | Samples a STRDS at vector points and returns aggregated values  to stdout or in the attribute table | Samples STRDSs at points from a vector map and outputs a STVDS | Samples a STRDS at the spatio-temporal locations of a STVDS |\n",
    "| input | vector (points) or coordinates and strds | vector (points) and strds | vector (points) and strds(s) | stvds (points) and strds |\n",
    "| output | stdout or plain text file | vector, plain text or stdout | stvds | stvds |\n",
    "| where | yes |  | yes | yes |\n",
    "| t_where |  |  |  | yes |\n",
    "| spatial aggr |  |  |  |  |\n",
    "| temporal aggr |  | yes |  | yes |\n",
    "| example | t.rast.what -n strds=A points=points output=result.txt layout=row | t.rast.what.aggr input=points strds=A date=\"2015-05-01\" granularity=\"2 months\" | t.vect.observe.strds input=points strds=A output=points_stvds vector_output=points_vector columns=A_values | t.vect.what.strds input=points strds=A column=A_values method=average |\n",
    "\n",
    "Let's see some examples. We will first randomly extract the centroids of 15 \n",
    "Italian regions in our study area and save them as a point vector map to\n",
    "query the raster time series afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 15 random points and add attr table\n",
    "gs.run_command(\"v.random\", \n",
    "               output=\"sampling_points\",\n",
    "               npoints=15,\n",
    "               restrict=\"italy_borders_2_clip\",\n",
    "               seed=47)\n",
    "gs.run_command(\"v.db.addtable\",\n",
    "               map=\"sampling_points\",\n",
    "               columns=\"cat integer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display polygons and points\n",
    "points = gj.Map(height = 500)\n",
    "points.d_vect(map=\"italy_borders_2_clip\", type=\"boundary\")\n",
    "points.d_vect(map=\"sampling_points\", icon=\"basic/circle\", size=8)\n",
    "points.d_barscale()\n",
    "points.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save map\n",
    "points.save(\"points.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate monthly LST time series\n",
    "gs.run_command(\"t.rast.aggregate\", \n",
    "               input=\"lst_daily\", \n",
    "               output=\"lst_monthly\",\n",
    "               basename=\"lst_monthly\",\n",
    "               granularity=\"1 month\",\n",
    "               suffix=\"gran\",\n",
    "               method=\"average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by using *t.rast.what* that will output the result in the standard\n",
    "output, i.e., the terminal, the GUI console or the Jupyter cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get LST monthly values for the points\n",
    "gs.run_command(\"t.rast.what\",\n",
    "               points=\"sampling_points\",\n",
    "               strds=\"lst_monthly\",\n",
    "               layout=\"row\",\n",
    "               flags=\"n\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x|y|start|end|value\n",
    "4577892.8167900704|2607156.3643725100|2014-01-01 00:00:00|2014-02-01 00:00:00|-3.3495627520159\n",
    "4577892.8167900704|2607156.3643725100|2014-02-01 00:00:00|2014-03-01 00:00:00|-4.49710379464276\n",
    "4577892.8167900704|2607156.3643725100|2014-03-01 00:00:00|2014-04-01 00:00:00|2.75497920866939\n",
    "4577892.8167900704|2607156.3643725100|2014-04-01 00:00:00|2014-05-01 00:00:00|5.8034850260417\n",
    "4577892.8167900704|2607156.3643725100|2014-05-01 00:00:00|2014-06-01 00:00:00|9.28137663810487\n",
    "4577892.8167900704|2607156.3643725100|2014-06-01 00:00:00|2014-07-01 00:00:00|13.8477356770834\n",
    "4577892.8167900704|2607156.3643725100|2014-07-01 00:00:00|2014-08-01 00:00:00|15.1575793850807\n",
    "4577892.8167900704|2607156.3643725100|2014-08-01 00:00:00|2014-09-01 00:00:00|13.6287058971774\n",
    "4577892.8167900704|2607156.3643725100|2014-09-01 00:00:00|2014-10-01 00:00:00|11.6199055989584\n",
    "4577892.8167900704|2607156.3643725100|2014-10-01 00:00:00|2014-11-01 00:00:00|8.36024697580648\n",
    "4577892.8167900704|2607156.3643725100|2014-11-01 00:00:00|2014-12-01 00:00:00|2.6866315104167\n",
    "4577892.8167900704|2607156.3643725100|2014-12-01 00:00:00|2015-01-01 00:00:00|-1.45273122479836\n",
    "4577892.8167900704|2607156.3643725100|2015-01-01 00:00:00|2015-02-01 00:00:00|-3.12071761592739"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-note title=\"Layouts\"}\n",
    "Users can then play around with the different output layouts, i.e., \n",
    "*row, column, timerow*, to find the one that better suits their data\n",
    "pipelines. \n",
    ":::\n",
    "\n",
    "Now, to exemplify the use of *t.rast.what.aggr* imagine we did some mosquito\n",
    "trappings in two different dates and we need to know which was the average\n",
    "LST the two months before the trappings. Since the dates are different, we\n",
    "actually need to aggregate different days. This is done on the fly (i.e., \n",
    "without the need to aggregate the whole raster time series) by the extension \n",
    "*t.rast.what.aggr*. Let's install it and add dates to our point vector map.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install t.rast.what.aggr extension\n",
    "gs.run_command(\"g.extension\", extension=\"t.rast.what.aggr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new date type column\n",
    "gs.run_command(\"v.db.addcolumn\", \n",
    "               map=\"sampling_points\",\n",
    "               column=\"sampling_date date\")\n",
    "               \n",
    "# Add values to the date column\n",
    "gs.run_command(\"v.db.update\", \n",
    "               map=\"sampling_points\", \n",
    "               column=\"sampling_date\",\n",
    "               value=\"2018-07-01\")\n",
    "gs.run_command(\"v.db.update\",\n",
    "               map=\"sampling_points\",\n",
    "               column=\"sampling_date\",\n",
    "               value=\"2018-08-10\",\n",
    "               where=\"cat >= '9'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect dates\n",
    "gs.vector_db_select(\"sampling_points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the daily time series in this case to get the aggregation \n",
    "period right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get aggregated LST values\n",
    "gs.run_command(\"t.rast.what.aggr\", \n",
    "               input=\"sampling_points\", \n",
    "               strds=\"lst_daily\", \n",
    "               date_column=\"sampling_date\",\n",
    "               granularity=\"2 months\",\n",
    "               method=\"average\",\n",
    "               flags=\"c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display the result by converting the attribute table into a Pandas \n",
    "DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = gs.parse_command(\"v.db.select\", \n",
    "                        map=\"sampling_points\", \n",
    "                        format=\"json\")\n",
    "                        \n",
    "pd.DataFrame(data['records'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-note title=\"Question\"}\n",
    "What would be the result if we use the monthly time series?\n",
    ":::\n",
    "\n",
    "Let's demonstrate now the use of *t.vect.observe.strds* and \n",
    "*t.vect.what.strds*. These tools, as mentioned above, output a vector \n",
    "time series or stvds. Vector time series in GRASS GIS can be created either \n",
    "from a series of vector maps (especially if features/geometries vary in time) \n",
    "or from layers added to a single vector map (i.e., features are always the \n",
    "same, as in the case of meteorological stations).\n",
    "\n",
    "We start with *t.vect.observe.strds*. It will create a new vector map with \n",
    "as many layers as raster maps there are in the strds we are querying and it \n",
    "will register these in a stvds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.run_command(\"t.vect.observe.strds\",\n",
    "               input=\"sampling_points\",\n",
    "               strds=\"lst_monthly\",\n",
    "               output=\"sp_lst_monthly\",\n",
    "               vector_output=\"sp_lst_monthly\",\n",
    "               columns=\"lst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the stvds is created\n",
    "gs.run_command(\"t.info\",\n",
    "               input=\"sp_lst_monthly\",\n",
    "               type=\"stvds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of layers in the vector map\n",
    "gs.vector_info(\"sp_lst_monthly\")[\"num_dblinks\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check one layer\n",
    "gs.vector_db_select(\"sp_lst_monthly\", layer=7)[\"values\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check all layers\n",
    "gs.run_command(\"t.vect.db.select\",\n",
    "               input=\"sp_lst_monthly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now compare the values obtained by querying the monthly LST time series\n",
    "with those resulting from aggregating the daily LST time series. They should \n",
    "be the same. For that we need to specify the sampling relation. The temporal \n",
    "tool that allows to specify sampling relations and do temporal aggregation is\n",
    "*t.vect.what.strds*. It requires a stvds as input, so we'll use the one we \n",
    "just obtained above. We also specify the *start* relation, so all maps in the \n",
    "strds which start time matches the stvds will be aggregated. Let's see this \n",
    "graphically before running the tool.\n",
    "\n",
    "![](img/comparison_of_granularities.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.run_command(\"t.vect.what.strds\", \n",
    "               input=\"sp_lst_monthly\", \n",
    "               strds=\"lst_daily\", \n",
    "               column=\"lst_new\", \n",
    "               method=\"average\", \n",
    "               sampling=\"start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gs.run_command(\"t.vect.db.select\",\n",
    "               input=\"sp_lst_monthly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, results are exactly the same! So, if you are constrained by disk\n",
    "space for example, you don't need to aggregate your entire strds if you only\n",
    "need aggregated values for a set of points.\n",
    "\n",
    "\n",
    "## Vector tools\n",
    "\n",
    "The main difference between temporal and vector tools to query raster time\n",
    "series is that vector tools can update the attribute table of the input vector\n",
    "without creating more layers. Regarding inputs, both *v.what.strds* and \n",
    "*v.what.strds.timestamp* take a point vector map as input, while *v.strds.stats*\n",
    "takes a line or polygon vector map and performs spatial aggregation, \n",
    "i.e. zonal stats over the full or a part of the strds. \n",
    "The extension *v.what.strds.timestamp*, somehow similar to *t.rast.what.aggr*,\n",
    "offers the possibility of reading input points' date information from a column\n",
    "in the attribute table and only performs the query for the dates that match. It\n",
    "also offers spatial interpolation of the four nearest pixels.\n",
    "\n",
    "\n",
    ": Comparison of vector tools that allow to query space time raster datasets.\n",
    "\n",
    "| Tools/<br>options | [v.what.strds](https://grass.osgeo.org/grass-stable/manuals/v.what.strds.html) | [v.what.strds.timestamp](https://grass.osgeo.org/grass-stable/manuals/addons/v.what.strds.timestamp.html) | [v.strds.stats](https://grass.osgeo.org/grass-stable/manuals/addons/v.strds.stats.html) |\n",
    "|---|---|---|---|\n",
    "| Purpose | Retrieves raster values from STRDSs using a point vector map | Matches points with timestamp in the attribute table with STRDSs based on point locations in space and time, and updates the input vector's attribute table | Calculates zonal statistics from STRDSs and uploads values to attribute columns of a new vector map |\n",
    "| input | vector (points) and strds(s) | vector (points) and strds(s) | vector (lines or polygons) and strds(s) |\n",
    "| output | vector | vector | vector |\n",
    "| where | yes | yes | yes |\n",
    "| t_where | yes | yes | yes |\n",
    "| spatial aggr |  |  | yes |\n",
    "| temporal aggr |  |  |  |\n",
    "| spatial interp | | yes | |\n",
    "| example | v.what.strds -u input=points strds=A  | v.what.strds.timestamp input=points timestamp_column=sampling_time column=A_at_sampling_time strds=A | v.strds.stats input=areas strds=A output=areas_new method=average |\n",
    "\n",
    "\n",
    "Let's go through the usage of the vector tools to query raster time series now.\n",
    "When we run *v.what.strds* to query strds we can either save the results in \n",
    "a new vector map or update the input vector attribute table by setting the\n",
    "`u` flag. In this case, we'll create a new vector map and do a temporal\n",
    "selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run v.what.strds with temporal selection\n",
    "gs.run_command(\"v.what.strds\",\n",
    "               input=\"sampling_points\",\n",
    "               strds=\"lst_monthly\",\n",
    "               output=\"sp_lst_monthly_2014\",\n",
    "               t_where=\"start_time <= '2015-01-01'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the new vector created. It contains a new column per map in the \n",
    "queried strds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = gs.parse_command(\"v.db.select\", \n",
    "                        map=\"sp_lst_monthly_2014\", \n",
    "                        format=\"json\")\n",
    "                        \n",
    "pd.DataFrame(data['records'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tool *v.what.strds.timestamp* is an extension so we need to install it first.\n",
    "It will by default update the input vector attribute table with a column that \n",
    "needs to be specified by the user. Furthermore, it offers spatial interpolation \n",
    "of the four nearest cells via the `i` flag. Let's compare the results with and\n",
    "without it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.run_command(\"g.extension\", extension=\"v.what.strds.timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with spatial interp of neighbor cells\n",
    "gs.run_command(\"v.what.strds.timestamp\",\n",
    "               input=\"sampling_points\",\n",
    "               timestamp_column=\"sampling_date\",\n",
    "               column=\"lst_sampling_date_i\",\n",
    "               strds=\"lst_daily\",\n",
    "               flags=\"i\")\n",
    "               \n",
    "# without spatial interp of neighbor cells\n",
    "gs.run_command(\"v.what.strds.timestamp\",\n",
    "               input=\"sampling_points\",\n",
    "               timestamp_column=\"sampling_date\",\n",
    "               column=\"lst_sampling_date_no_i\",\n",
    "               strds=\"lst_daily\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = gs.parse_command(\"v.db.select\", \n",
    "                        map=\"sampling_points\", \n",
    "                        format=\"json\")\n",
    "                        \n",
    "pd.DataFrame(data['records'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll extract zonal statistics of a raster time series. For this, we\n",
    "need either a line or polygon vector map as input. We'll use the map of\n",
    "italian municipalities and demonstrate the use of spatial (`where`) and temporal \n",
    "(`t_where`) selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install v.strds.stats extension\n",
    "gs.run_command(\"g.extension\", extension=\"v.strds.stats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract August average LST for Milano municipality\n",
    "gs.run_command(\"v.strds.stats\",\n",
    "               input=\"italy_borders_3\",\n",
    "               strds=\"lst_monthly\",\n",
    "               where=\"NAME_3 == 'Milano'\",\n",
    "               t_where=\"strftime('%m', start_time)='08'\",\n",
    "               output=\"milano_lst_august\",\n",
    "               method=\"average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.vector_db_select(\"milano_lst_august\")[\"values\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try to find out which municipality in northern Italy had the highest \n",
    "August average temperature each year? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip municipalities to computational region\n",
    "gs.run_command(\"v.clip\", \n",
    "               input=\"italy_borders_3\", \n",
    "               output=\"italy_borders_3_clip\", \n",
    "               flags=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract summer average LST municipalities\n",
    "gs.run_command(\"v.strds.stats\",\n",
    "               input=\"italy_borders_3_clip\",\n",
    "               strds=\"lst_monthly\",\n",
    "               t_where=\"strftime('%m', start_time)='08'\",\n",
    "               output=\"municip_lst_august\",\n",
    "               method=\"average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the output table\n",
    "data = gs.parse_command(\"v.db.select\", \n",
    "                        map=\"municip_lst_august\", \n",
    "                        format=\"json\")\n",
    "                        \n",
    "table = pd.DataFrame(data['records'])\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List with column names\n",
    "cols = list(table.columns[-5:])\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}\n",
    "\n",
    "for col in cols:\n",
    "    # Find the maximum value in the column\n",
    "    max_value = table[col].max()\n",
    "    \n",
    "    # Find the index of the row with the maximum value\n",
    "    max_index = table[col].idxmax()\n",
    "    \n",
    "    # Find the corresponding value in column 'D'\n",
    "    municipality = table.loc[max_index, \"NAME_3\"]\n",
    "    \n",
    "    # Store the results\n",
    "    results[col] = {'max_value': max_value, 'municipality': municipality}\n",
    "\n",
    "# Display the results\n",
    "for col, res in results.items():\n",
    "    print(f\"Column '{col}':\")\n",
    "    print(f\"  Maximum value: {res['max_value']}\")\n",
    "    print(f\"  Municipality name: {res['municipality']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest average temperature in August varied among years and municipalities, however, Campi Bisenzio in the province of Florence, had the highest value both in 2016 and 2017.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- how to get the max of each new col -->\n",
    "\n",
    "<!-- write the result -->\n",
    "\n",
    "\n",
    "## References\n",
    "\n",
    "\n",
    ":::{.smaller}\n",
    "Development of this tutorial was funded by the US \n",
    "[National Science Foundation (NSF)](https://www.nsf.gov/), \n",
    "award [2303651](https://www.nsf.gov/awardsearch/showAward?AWD_ID=2303651).\n",
    ":::"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
